{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T10:43:38.737126Z","iopub.status.busy":"2023-05-09T10:43:38.736584Z","iopub.status.idle":"2023-05-09T10:43:38.743491Z","shell.execute_reply":"2023-05-09T10:43:38.741928Z","shell.execute_reply.started":"2023-05-09T10:43:38.737055Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np \n","import matplotlib.pyplot as plt\n","import os\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Import with ID"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T10:43:38.745755Z","iopub.status.busy":"2023-05-09T10:43:38.745258Z","iopub.status.idle":"2023-05-09T10:43:38.765496Z","shell.execute_reply":"2023-05-09T10:43:38.764307Z","shell.execute_reply.started":"2023-05-09T10:43:38.745714Z"},"trusted":true},"outputs":[],"source":["# def preprocess_the_whole_stage(folder_path):\n","#     # create an empty list to store the DataFrames\n","#     dfs = []\n","\n","#     # loop over all files in the folder\n","#     for filename in os.listdir(folder_path):\n","#         if filename.endswith(\".csv\"):\n","#             # extract the ID from the filename (assuming the filename is in the format \"ID.csv\")\n","#             file_id = os.path.splitext(filename)[0]\n","\n","#             # read the CSV file into a DataFrame and add the ID as a new column\n","#             df = pd.read_csv(os.path.join(folder_path, filename))\n","#             df.insert(0, 'ID', file_id)\n","\n","#             # append the DataFrame to the list\n","#             dfs.append(df)\n","\n","#     # concatenate all DataFrames into a single DataFrame\n","#     full_dataset = pd.concat(dfs)\n","    \n","#     # print the resulting DataFrame\n","#     print(full_dataset.head())\n","    \n","#     # Add all zero class\n","#     condition = (full_dataset.StartHesitation == 0) & (full_dataset.Turn == 0) & (full_dataset.Walking == 0)\n","#     condition_2 = (full_dataset.StartHesitation == 1) | (full_dataset.Turn == 1) | (full_dataset.Walking == 1)\n","    \n","#     full_dataset.loc[condition, 'All_zero'] = 1\n","#     full_dataset.loc[condition_2, 'All_zero'] = 0\n","#     print(full_dataset.head())\n","    \n","#     print(\"Cleaning the Dataset\")\n","#     if 'Valid' in full_dataset.columns:\n","#         remove_col = ['ID','Time', 'Valid', 'Task']\n","        \n","#     else:\n","#         remove_col = ['ID','Time']\n","#     print(f\"The remove columns : {remove_col}\")\n","#     clean_dataset = full_dataset.drop(full_dataset[remove_col],axis=1)\n","#     print(clean_dataset.head())\n","    \n","#     # search duplication\n","#     print(f\"Search for Duplication : {clean_dataset.duplicated().sum()}\")\n","#     clean_dataset.drop_duplicates(inplace=True)\n","#     print(f\"Search for Duplication : {clean_dataset.duplicated().sum()}\")\n","#     print(clean_dataset.head())\n","    \n","#     print(\"Checking conditon\")\n","#     condition = (clean_dataset.StartHesitation == 0) & (clean_dataset.Turn == 0 ) & (clean_dataset.Walking == 0)\n","#     total_zero = clean_dataset[condition].shape[0]\n","#     print(f\"Total number where three class are zero: {total_zero}\")\n","#     All_zero = clean_dataset[clean_dataset.All_zero == 1].shape[0]\n","#     print(f\"Total number of All_zero class: {All_zero}\")\n","#     print(f\"Is all zero and Total number zero are equal :{All_zero == total_zero}\")\n","#     a = clean_dataset[clean_dataset.StartHesitation == 1].shape[0]\n","#     print(f\"The number of Class Start Hesitation :{a}\")\n","#     b = clean_dataset[clean_dataset.Walking == 1].shape[0]\n","#     print(f\"The number of Class Walking :{b}\")\n","#     c = clean_dataset[clean_dataset.Turn == 1].shape[0]\n","#     print(f\"The number of Class Turn : {c}\")\n","#     print(f\"Is the toatl number of sample equal to all Four class combine :\"\n","#          f\"{clean_dataset.shape[0] == a + b + c + All_zero}\")\n","    \n","#     return clean_dataset\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T10:43:38.770901Z","iopub.status.busy":"2023-05-09T10:43:38.770314Z","iopub.status.idle":"2023-05-09T10:43:38.784366Z","shell.execute_reply":"2023-05-09T10:43:38.783293Z","shell.execute_reply.started":"2023-05-09T10:43:38.770852Z"},"trusted":true},"outputs":[],"source":["# def oversampling_and_split(clean_dataset):\n","#     feature_col = ['AccV','AccML','AccAP']\n","#     label_col = ['StartHesitation','Turn','Walking', 'All_zero']\n","\n","#     feature_dataset = clean_dataset[feature_col]\n","#     label_dataset = clean_dataset[label_col]\n","#     print(f\"The Feature :{feature_dataset.shape}, \\n\"\n","#           f\"The label {label_dataset.shape}\")\n","    \n","#     print(f\"Because of Four Classes are imbalanced. To get high accuracy, oversampling is used\")\n","#     from imblearn.over_sampling import SMOTE\n","#     import numpy as np\n","#     # Instantiate the MultiLabelUnderSampler\n","#     over_sampler = SMOTE()\n","\n","#     # Undersample the dataset\n","#     X_resampled, y_resampled = over_sampler.fit_resample(feature_dataset.to_numpy(), label_dataset.to_numpy())\n","    \n","#     SMOTE_features_dataset = pd.DataFrame(X_resampled, columns=feature_dataset.columns)\n","    \n","    \n","#     SMOTE_labels_dataset = pd.DataFrame(y_resampled, columns=label_dataset.columns)\n","#     print(f\"The over sampling label shape : {SMOTE_labels_dataset.shape}\")\n","    \n","#     def check_all_four_class_condition(df):\n","#         print(f\"Check all four check condiiton in {df}\")\n","#         a = df[df.StartHesitation == 1].shape[0]\n","#         b = df[df.Turn == 1].shape[0]\n","#         c = df[df.Walking ==1].shape[0]\n","#         d = df[df.All_zero == 1].shape[0]\n","#         print(f\"Number of Start Hesitation : {a}, \\n\"\n","#               f\"Number of Turn : {b}, \\n\"  \n","#               f\"Number of Walking : {c}, \\n\"\n","#               f\"Number of All_zero : {d}\")\n","#         print(\"Is Number of All four class is equal to total sampling :\",\n","#              df.shape[0] == a + b + c + d)\n","        \n","#     check_all_four_class_condition(SMOTE_labels_dataset)\n","    \n","#     oversampling_dataset = pd.concat([SMOTE_features_dataset,SMOTE_labels_dataset], \n","#                                      ignore_index= False, sort=False, axis=1)\n","#     print(f\"The shape of oversampling dataset is : {oversampling_dataset.shape[0]}\")\n","#     print(f\"The number of duplication in dataset : {oversampling_dataset.duplicated().sum()}\")\n","#     # Drop duplication\n","#     oversampling_dataset.drop_duplicates(inplace=True)\n","#     print(f\"The shape of oversampling after remove duplication :{oversampling_dataset.shape}\")\n","    \n","#     # 60% Train Data, 20% Validation Data, 20% Test Data\n","#     # 80% Set Data(60% rain Data, 20% Validation Data) , 20% Test Data\n","    \n","#     from sklearn.model_selection import train_test_split\n","#     import random \n","#     random_seed = 54\n","\n","#     set_data, test_data = train_test_split(oversampling_dataset, test_size=0.2, random_state=True)\n","#     print(f\"The set data shape : {set_data.shape}\\n\"\n","#           f\"The test data shape : {test_data.shape}\\n\"\n","#           f\"Is the dataset still in range : \"\n","#           f\"{oversampling_dataset.shape[0] == set_data.shape[0] + test_data.shape[0]}\")\n","    \n","#     print(f\"Again Search for duplicaiton : \\n \"\n","#           f\"Set Data :{set_data.duplicated().sum()} \\n\"\n","#           f\"Test Data :{test_data.duplicated().sum()}\")\n","    \n","#     check_all_four_class_condition(set_data)\n","#     check_all_four_class_condition(test_data)\n","#     print(\"All task are finish\")\n","    \n","#     return set_data, test_data\n","    "]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T10:43:38.926021Z","iopub.status.busy":"2023-05-09T10:43:38.924800Z","iopub.status.idle":"2023-05-09T10:43:38.934262Z","shell.execute_reply":"2023-05-09T10:43:38.932862Z","shell.execute_reply.started":"2023-05-09T10:43:38.925960Z"},"trusted":true},"outputs":[],"source":["# def preprocessing_the_dataset(df):\n","# #     def check_skewness(df):\n","# #     # this can check relation between each column\n","# #         skew_limit=0.75\n","# #         skew_value=df[df.columns].skew()\n","# #         #print(skew_value)\n","# #         skew_col=skew_value[abs(skew_value)>skew_limit]\n","# #         cols=skew_col.index\n","# #         return cols\n","\n","#     import random \n","#     random_seed = 54\n","    \n","#     feature_col = ['AccV','AccML','AccAP']\n","#     label_col = ['StartHesitation','Turn','Walking', 'All_zero']\n","\n","#     # make feature and label\n","#     feature_dataset = df[feature_col]\n","#     label_dataset = df[label_col]\n","    \n","# #     # check skewness and powertransform\n","# #     skew_columns = check_skewness(feature_dataset)\n","# #     print(skew_columns)\n","    \n","# #     print(\"Power Transform start\")\n","# #     from sklearn.preprocessing import PowerTransformer\n","# #     pt=PowerTransformer(standardize=False)  \n","# #     feature_dataset[skew_columns] = pt.fit_transform(feature_dataset[skew_columns])\n","    \n","# #     print(\"Standardization start\")\n","# #     # Change features data to 0 and 1\n","# #     from sklearn.preprocessing import StandardScaler\n","# #     sc=StandardScaler()\n","# #     feature_dataset=sc.fit_transform(feature_dataset)\n","    \n","#     print(\"Train test split begin\")\n","#     from sklearn.model_selection import train_test_split\n","#     train_feature, valid_feature, train_label, valid_label = train_test_split(feature_dataset, label_dataset, test_size=0.2, random_state=True)\n","    \n","#     train_feature = np.array(train_feature) \n","#     valid_feature = np.array(valid_feature)\n","#     train_label  = np.array(train_label)\n","#     valid_label = np.array(valid_label)\n","#     print(\"All task are finish\")\n","    \n","#     return train_feature, valid_feature, train_label, valid_label\n","    "]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# def preprocessing_test_dataset(df):\n","\n","#     import random \n","#     random_seed = 54\n","    \n","#     feature_col = ['AccV','AccML','AccAP']\n","#     label_col = ['StartHesitation','Turn','Walking', 'All_zero']\n","\n","#     # make feature and label\n","#     feature_dataset = df[feature_col]\n","#     label_dataset = df[label_col]\n","    \n","#     feature_dataset = np.array(feature_dataset) \n","#     label_dataset  = np.array(label_dataset)\n","#     print(\"All task are finish\")\n","    \n","#     return feature_dataset, label_dataset"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Import Defog Dataset"]},{"cell_type":"code","execution_count":7,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-05-09T10:43:38.937635Z","iopub.status.busy":"2023-05-09T10:43:38.937051Z","iopub.status.idle":"2023-05-09T10:45:42.854023Z","shell.execute_reply":"2023-05-09T10:45:42.852833Z","shell.execute_reply.started":"2023-05-09T10:43:38.937568Z"},"trusted":true},"outputs":[],"source":["# # specify the folder path\n","# defog_path = \"Data/train/defog\"\n","# clean_defog_dataset = preprocess_the_whole_stage(defog_path)\n","# tdcsfog_path = \"Data/train/tdcsfog\"\n","# clean_tdcsfog_dataset= preprocess_the_whole_stage(tdcsfog_path)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Mix two dataset and oversplit"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T10:45:42.904310Z","iopub.status.busy":"2023-05-09T10:45:42.903890Z","iopub.status.idle":"2023-05-09T10:45:43.487819Z","shell.execute_reply":"2023-05-09T10:45:43.486504Z","shell.execute_reply.started":"2023-05-09T10:45:42.904278Z"},"trusted":true},"outputs":[],"source":["# clean_dataset = pd.concat([clean_tdcsfog_dataset, clean_defog_dataset ], \n","#                            ignore_index= True, sort=False, axis=0)\n","# set_data,test_data = oversampling_and_split(clean_dataset)\n","# train_feature, valid_feature, train_label, valid_label = preprocessing_the_dataset(set_data)\n","# print(f\"{train_feature.shape} , {train_label.shape} , {valid_feature.shape} , {valid_label.shape}, {test_data.shape}\")\n","# test_feature, test_label = preprocessing_test_dataset(test_data)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# np.save('Data/mix/train_feature.npy',train_feature) \n","# np.save('Data/mix/valid_feature.npy', valid_feature)\n","# np.save('Data/mix/train_label.npy', train_label)\n","# np.save('Data/mix/valid_label.npy',valid_label)\n","# np.save('Data/mix/test_feature.npy',test_feature)\n","# np.save('Data/mix/test_label.npy',test_label)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["train_feature = np.load('Data/mix/train_feature.npy')\n","valid_feature = np.load('Data/mix/valid_feature.npy')\n","test_feature = np.load('Data/mix/test_feature.npy')\n","train_label = np.load('Data/mix/train_label.npy')\n","valid_label = np.load('Data/mix/valid_label.npy')\n","test_label = np.load('Data/mix/test_label.npy')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Build Model"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T10:54:56.710486Z","iopub.status.busy":"2023-05-09T10:54:56.710154Z","iopub.status.idle":"2023-05-09T10:54:56.719769Z","shell.execute_reply":"2023-05-09T10:54:56.718394Z","shell.execute_reply.started":"2023-05-09T10:54:56.710459Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import accuracy_score\n","from sklearn.metrics import balanced_accuracy_score\n","from sklearn.metrics import average_precision_score\n","from sklearn.metrics import classification_report\n","\n","def eval_metrics(classifier, test_features, test_labels):\n","    \n","    # make prediction\n","    predictions   = classifier.predict(test_features)\n","    \n","    base_score   = classifier.score(test_features, test_labels)\n","    accuracy = accuracy_score(test_labels, predictions)\n","    av_precision = average_precision_score(test_labels, predictions)\n","    \n","    target_names = ['StartHesitation','Turn','Walking', 'All_zero']\n","    print(\"Classification report\")\n","    print(\"---------------------\",\"\\n\")\n","    print(classification_report(test_labels, predictions, target_names=target_names),\"\\n\")\n","\n","    print(\"Accuracy Measures\")\n","    print(\"---------------------\",\"\\n\")\n","    print(\"Base score: \", base_score)\n","    print(\"Accuracy: \", accuracy)\n","    print(\"Avarge Precision: \", av_precision)\n","    \n","    return base_score,accuracy,av_precision"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T10:54:56.721656Z","iopub.status.busy":"2023-05-09T10:54:56.721306Z","iopub.status.idle":"2023-05-09T10:54:56.732603Z","shell.execute_reply":"2023-05-09T10:54:56.731199Z","shell.execute_reply.started":"2023-05-09T10:54:56.721628Z"},"trusted":true},"outputs":[],"source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.neighbors import  RadiusNeighborsClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import ExtraTreesClassifier\n","from sklearn.neural_network import MLPClassifier\n","import xgboost as xgb\n","from catboost import Pool, CatBoostClassifier, cv\n","\n","\n","#Building Model Dict\n","Models = {                         \n","    \"Decision Tree\": DecisionTreeClassifier(),      \n","    \"KNearest\": KNeighborsClassifier(n_jobs=-1),           \n","    # \"Ridge\" : RidgeClassifier(),              #poor result    \n","    \"MLP\" : MLPClassifier(),                  #poor result              \n","    # \"R_Neighour\" : RadiusNeighborsClassifier(),\n","    # \"Extra_T\" : ExtraTreesClassifier(),\n","    # \"R_forest\" : RandomForestClassifier(),\n","    \"XGB\" : xgb.XGBClassifier(),\n","    # \"Catboost\" : CatBoostClassifier()\n","    }"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tracking URI: 'http://127.0.0.1:5000'\n"]}],"source":["import mlflow\n","import mlflow.tensorflow\n","mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n","print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\")"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1. Decision Tree\n"]},{"ename":"MlflowException","evalue":"API request to http://127.0.0.1:5000/api/2.0/mlflow/runs/create failed with exception HTTPConnectionPool(host='127.0.0.1', port=5000): Max retries exceeded with url: /api/2.0/mlflow/runs/create (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa66bd76680>: Failed to establish a new connection: [Errno 111] Connection refused'))","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)","File \u001b[0;32m~/miniconda3/envs/main/lib/python3.10/site-packages/urllib3/connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     conn \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mcreate_connection(\n\u001b[1;32m    175\u001b[0m         (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dns_host, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_kw\n\u001b[1;32m    176\u001b[0m     )\n\u001b[1;32m    178\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout:\n","File \u001b[0;32m~/miniconda3/envs/main/lib/python3.10/site-packages/urllib3/util/connection.py:95\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39mif\u001b[39;00m err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 95\u001b[0m     \u001b[39mraise\u001b[39;00m err\n\u001b[1;32m     97\u001b[0m \u001b[39mraise\u001b[39;00m socket\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mgetaddrinfo returns an empty list\u001b[39m\u001b[39m\"\u001b[39m)\n","File \u001b[0;32m~/miniconda3/envs/main/lib/python3.10/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m     sock\u001b[39m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 85\u001b[0m sock\u001b[39m.\u001b[39;49mconnect(sa)\n\u001b[1;32m     86\u001b[0m \u001b[39mreturn\u001b[39;00m sock\n","\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)","File \u001b[0;32m~/miniconda3/envs/main/lib/python3.10/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/main/lib/python3.10/site-packages/urllib3/connectionpool.py:398\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 398\u001b[0m         conn\u001b[39m.\u001b[39;49mrequest(method, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhttplib_request_kw)\n\u001b[1;32m    400\u001b[0m \u001b[39m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[39m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[39m# With this behaviour, the received response is still readable.\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/main/lib/python3.10/site-packages/urllib3/connection.py:239\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers)\u001b[0m\n\u001b[1;32m    238\u001b[0m     headers[\u001b[39m\"\u001b[39m\u001b[39mUser-Agent\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m _get_default_user_agent()\n\u001b[0;32m--> 239\u001b[0m \u001b[39msuper\u001b[39;49m(HTTPConnection, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mrequest(method, url, body\u001b[39m=\u001b[39;49mbody, headers\u001b[39m=\u001b[39;49mheaders)\n","File \u001b[0;32m~/miniconda3/envs/main/lib/python3.10/http/client.py:1282\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1282\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_request(method, url, body, headers, encode_chunked)\n","File \u001b[0;32m~/miniconda3/envs/main/lib/python3.10/http/client.py:1328\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1327\u001b[0m     body \u001b[39m=\u001b[39m _encode(body, \u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1328\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendheaders(body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n","File \u001b[0;32m~/miniconda3/envs/main/lib/python3.10/http/client.py:1277\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[39mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1277\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_output(message_body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n","File \u001b[0;32m~/miniconda3/envs/main/lib/python3.10/http/client.py:1037\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1036\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1037\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(msg)\n\u001b[1;32m   1039\u001b[0m \u001b[39mif\u001b[39;00m message_body \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1040\u001b[0m \n\u001b[1;32m   1041\u001b[0m     \u001b[39m# create a consistent interface to message_body\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/main/lib/python3.10/http/client.py:975\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_open:\n\u001b[0;32m--> 975\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m    976\u001b[0m \u001b[39melse\u001b[39;00m:\n","File \u001b[0;32m~/miniconda3/envs/main/lib/python3.10/site-packages/urllib3/connection.py:205\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 205\u001b[0m     conn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[1;32m    206\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_conn(conn)\n","File \u001b[0;32m~/miniconda3/envs/main/lib/python3.10/site-packages/urllib3/connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[39mexcept\u001b[39;00m SocketError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 186\u001b[0m     \u001b[39mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    187\u001b[0m         \u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFailed to establish a new connection: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m e\n\u001b[1;32m    188\u001b[0m     )\n\u001b[1;32m    190\u001b[0m \u001b[39mreturn\u001b[39;00m conn\n","\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x7fa66bd76680>: Failed to establish a new connection: [Errno 111] Connection refused","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)","File \u001b[0;32m~/miniconda3/envs/main/lib/python3.10/site-packages/requests/adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 489\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    490\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    491\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    492\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    493\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    494\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    496\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    497\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    498\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    499\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    500\u001b[0m     )\n\u001b[1;32m    502\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[39melse\u001b[39;00m:\n","File \u001b[0;32m~/miniconda3/envs/main/lib/python3.10/site-packages/urllib3/connectionpool.py:815\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    812\u001b[0m     log\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    813\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRetrying (\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m) after connection broken by \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, retries, err, url\n\u001b[1;32m    814\u001b[0m     )\n\u001b[0;32m--> 815\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    816\u001b[0m         method,\n\u001b[1;32m    817\u001b[0m         url,\n\u001b[1;32m    818\u001b[0m         body,\n\u001b[1;32m    819\u001b[0m         headers,\n\u001b[1;32m    820\u001b[0m         retries,\n\u001b[1;32m    821\u001b[0m         redirect,\n\u001b[1;32m    822\u001b[0m         assert_same_host,\n\u001b[1;32m    823\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    824\u001b[0m         pool_timeout\u001b[39m=\u001b[39;49mpool_timeout,\n\u001b[1;32m    825\u001b[0m         release_conn\u001b[39m=\u001b[39;49mrelease_conn,\n\u001b[1;32m    826\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    827\u001b[0m         body_pos\u001b[39m=\u001b[39;49mbody_pos,\n\u001b[1;32m    828\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw\n\u001b[1;32m    829\u001b[0m     )\n\u001b[1;32m    831\u001b[0m \u001b[39m# Handle redirect?\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/main/lib/python3.10/site-packages/urllib3/connectionpool.py:815\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    812\u001b[0m     log\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    813\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRetrying (\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m) after connection broken by \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, retries, err, url\n\u001b[1;32m    814\u001b[0m     )\n\u001b[0;32m--> 815\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    816\u001b[0m         method,\n\u001b[1;32m    817\u001b[0m         url,\n\u001b[1;32m    818\u001b[0m         body,\n\u001b[1;32m    819\u001b[0m         headers,\n\u001b[1;32m    820\u001b[0m         retries,\n\u001b[1;32m    821\u001b[0m         redirect,\n\u001b[1;32m    822\u001b[0m         assert_same_host,\n\u001b[1;32m    823\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    824\u001b[0m         pool_timeout\u001b[39m=\u001b[39;49mpool_timeout,\n\u001b[1;32m    825\u001b[0m         release_conn\u001b[39m=\u001b[39;49mrelease_conn,\n\u001b[1;32m    826\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    827\u001b[0m         body_pos\u001b[39m=\u001b[39;49mbody_pos,\n\u001b[1;32m    828\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw\n\u001b[1;32m    829\u001b[0m     )\n\u001b[1;32m    831\u001b[0m \u001b[39m# Handle redirect?\u001b[39;00m\n","    \u001b[0;31m[... skipping similar frames: HTTPConnectionPool.urlopen at line 815 (2 times)]\u001b[0m\n","File \u001b[0;32m~/miniconda3/envs/main/lib/python3.10/site-packages/urllib3/connectionpool.py:815\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    812\u001b[0m     log\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    813\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRetrying (\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m) after connection broken by \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, retries, err, url\n\u001b[1;32m    814\u001b[0m     )\n\u001b[0;32m--> 815\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    816\u001b[0m         method,\n\u001b[1;32m    817\u001b[0m         url,\n\u001b[1;32m    818\u001b[0m         body,\n\u001b[1;32m    819\u001b[0m         headers,\n\u001b[1;32m    820\u001b[0m         retries,\n\u001b[1;32m    821\u001b[0m         redirect,\n\u001b[1;32m    822\u001b[0m         assert_same_host,\n\u001b[1;32m    823\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    824\u001b[0m         pool_timeout\u001b[39m=\u001b[39;49mpool_timeout,\n\u001b[1;32m    825\u001b[0m         release_conn\u001b[39m=\u001b[39;49mrelease_conn,\n\u001b[1;32m    826\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    827\u001b[0m         body_pos\u001b[39m=\u001b[39;49mbody_pos,\n\u001b[1;32m    828\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw\n\u001b[1;32m    829\u001b[0m     )\n\u001b[1;32m    831\u001b[0m \u001b[39m# Handle redirect?\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/main/lib/python3.10/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m     e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, e)\n\u001b[0;32m--> 787\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[1;32m    788\u001b[0m     method, url, error\u001b[39m=\u001b[39;49me, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[1;32m    789\u001b[0m )\n\u001b[1;32m    790\u001b[0m retries\u001b[39m.\u001b[39msleep()\n","File \u001b[0;32m~/miniconda3/envs/main/lib/python3.10/site-packages/urllib3/util/retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[39mif\u001b[39;00m new_retry\u001b[39m.\u001b[39mis_exhausted():\n\u001b[0;32m--> 592\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[39mor\u001b[39;00m ResponseError(cause))\n\u001b[1;32m    594\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mIncremented Retry for (url=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m): \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, url, new_retry)\n","\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='127.0.0.1', port=5000): Max retries exceeded with url: /api/2.0/mlflow/runs/create (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa66bd76680>: Failed to establish a new connection: [Errno 111] Connection refused'))","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)","File \u001b[0;32m~/miniconda3/envs/main/lib/python3.10/site-packages/mlflow/utils/rest_utils.py:174\u001b[0m, in \u001b[0;36mhttp_request\u001b[0;34m(host_creds, endpoint, method, max_retries, backoff_factor, extra_headers, retry_codes, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     \u001b[39mreturn\u001b[39;00m _get_http_response_with_retries(\n\u001b[1;32m    175\u001b[0m         method,\n\u001b[1;32m    176\u001b[0m         url,\n\u001b[1;32m    177\u001b[0m         max_retries,\n\u001b[1;32m    178\u001b[0m         backoff_factor,\n\u001b[1;32m    179\u001b[0m         retry_codes,\n\u001b[1;32m    180\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    181\u001b[0m         verify\u001b[39m=\u001b[39;49mhost_creds\u001b[39m.\u001b[39;49mverify,\n\u001b[1;32m    182\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    183\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    184\u001b[0m     )\n\u001b[1;32m    185\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mTimeout \u001b[39mas\u001b[39;00m to:\n","File \u001b[0;32m~/miniconda3/envs/main/lib/python3.10/site-packages/mlflow/utils/rest_utils.py:105\u001b[0m, in \u001b[0;36m_get_http_response_with_retries\u001b[0;34m(method, url, max_retries, backoff_factor, retry_codes, cached_session, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m     session \u001b[39m=\u001b[39m _get_request_session_uncached(max_retries, backoff_factor, retry_codes)\n\u001b[0;32m--> 105\u001b[0m \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/miniconda3/envs/main/lib/python3.10/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n","File \u001b[0;32m~/miniconda3/envs/main/lib/python3.10/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/main/lib/python3.10/site-packages/requests/adapters.py:565\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[39mraise\u001b[39;00m SSLError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m--> 565\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m    567\u001b[0m \u001b[39mexcept\u001b[39;00m ClosedPoolError \u001b[39mas\u001b[39;00m e:\n","\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='127.0.0.1', port=5000): Max retries exceeded with url: /api/2.0/mlflow/runs/create (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa66bd76680>: Failed to establish a new connection: [Errno 111] Connection refused'))","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)","Cell \u001b[0;32mIn[16], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m Model_Name, classifier \u001b[39min\u001b[39;00m Models\u001b[39m.\u001b[39mitems(): \n\u001b[1;32m      3\u001b[0m     \u001b[39m# with mlflow.start_run(nested=True):\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mcounter\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m{\u001b[39;00mModel_Name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     \u001b[39mwith\u001b[39;00m mlflow\u001b[39m.\u001b[39;49mstart_run():\n\u001b[1;32m      7\u001b[0m         \u001b[39m# fit the model\u001b[39;00m\n\u001b[1;32m      8\u001b[0m         \u001b[39mfrom\u001b[39;00m \u001b[39mjoblib\u001b[39;00m \u001b[39mimport\u001b[39;00m parallel_backend\n\u001b[1;32m      9\u001b[0m         \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39m'\u001b[39m\u001b[39mthreading\u001b[39m\u001b[39m'\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n","File \u001b[0;32m~/miniconda3/envs/main/lib/python3.10/site-packages/mlflow/tracking/fluent.py:350\u001b[0m, in \u001b[0;36mstart_run\u001b[0;34m(run_id, experiment_id, run_name, nested, tags, description)\u001b[0m\n\u001b[1;32m    346\u001b[0m         user_specified_tags[MLFLOW_RUN_NAME] \u001b[39m=\u001b[39m run_name\n\u001b[1;32m    348\u001b[0m     resolved_tags \u001b[39m=\u001b[39m context_registry\u001b[39m.\u001b[39mresolve_tags(user_specified_tags)\n\u001b[0;32m--> 350\u001b[0m     active_run_obj \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mcreate_run(\n\u001b[1;32m    351\u001b[0m         experiment_id\u001b[39m=\u001b[39;49mexp_id_for_run, tags\u001b[39m=\u001b[39;49mresolved_tags, run_name\u001b[39m=\u001b[39;49mrun_name\n\u001b[1;32m    352\u001b[0m     )\n\u001b[1;32m    354\u001b[0m _active_run_stack\u001b[39m.\u001b[39mappend(ActiveRun(active_run_obj))\n\u001b[1;32m    355\u001b[0m \u001b[39mreturn\u001b[39;00m _active_run_stack[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n","File \u001b[0;32m~/miniconda3/envs/main/lib/python3.10/site-packages/mlflow/tracking/client.py:280\u001b[0m, in \u001b[0;36mMlflowClient.create_run\u001b[0;34m(self, experiment_id, start_time, tags, run_name)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_run\u001b[39m(\n\u001b[1;32m    230\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    231\u001b[0m     experiment_id: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     run_name: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    235\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Run:\n\u001b[1;32m    236\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[39m    Create a :py:class:`mlflow.entities.Run` object that can be associated with\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[39m    metrics, parameters, artifacts, etc.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39m        status: RUNNING\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 280\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tracking_client\u001b[39m.\u001b[39;49mcreate_run(experiment_id, start_time, tags, run_name)\n","File \u001b[0;32m~/miniconda3/envs/main/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/client.py:131\u001b[0m, in \u001b[0;36mTrackingServiceClient.create_run\u001b[0;34m(self, experiment_id, start_time, tags, run_name)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[39m# Extract user from tags\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[39m# This logic is temporary; the user_id attribute of runs is deprecated and will be removed\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[39m# in a later release.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m user_id \u001b[39m=\u001b[39m tags\u001b[39m.\u001b[39mget(MLFLOW_USER, \u001b[39m\"\u001b[39m\u001b[39munknown\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 131\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstore\u001b[39m.\u001b[39;49mcreate_run(\n\u001b[1;32m    132\u001b[0m     experiment_id\u001b[39m=\u001b[39;49mexperiment_id,\n\u001b[1;32m    133\u001b[0m     user_id\u001b[39m=\u001b[39;49muser_id,\n\u001b[1;32m    134\u001b[0m     start_time\u001b[39m=\u001b[39;49mstart_time \u001b[39mor\u001b[39;49;00m get_current_time_millis(),\n\u001b[1;32m    135\u001b[0m     tags\u001b[39m=\u001b[39;49m[RunTag(key, value) \u001b[39mfor\u001b[39;49;00m (key, value) \u001b[39min\u001b[39;49;00m tags\u001b[39m.\u001b[39;49mitems()],\n\u001b[1;32m    136\u001b[0m     run_name\u001b[39m=\u001b[39;49mrun_name,\n\u001b[1;32m    137\u001b[0m )\n","File \u001b[0;32m~/miniconda3/envs/main/lib/python3.10/site-packages/mlflow/store/tracking/rest_store.py:175\u001b[0m, in \u001b[0;36mRestStore.create_run\u001b[0;34m(self, experiment_id, user_id, start_time, tags, run_name)\u001b[0m\n\u001b[1;32m    165\u001b[0m tag_protos \u001b[39m=\u001b[39m [tag\u001b[39m.\u001b[39mto_proto() \u001b[39mfor\u001b[39;00m tag \u001b[39min\u001b[39;00m tags]\n\u001b[1;32m    166\u001b[0m req_body \u001b[39m=\u001b[39m message_to_json(\n\u001b[1;32m    167\u001b[0m     CreateRun(\n\u001b[1;32m    168\u001b[0m         experiment_id\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m(experiment_id),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    173\u001b[0m     )\n\u001b[1;32m    174\u001b[0m )\n\u001b[0;32m--> 175\u001b[0m response_proto \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_endpoint(CreateRun, req_body)\n\u001b[1;32m    176\u001b[0m run \u001b[39m=\u001b[39m Run\u001b[39m.\u001b[39mfrom_proto(response_proto\u001b[39m.\u001b[39mrun)\n\u001b[1;32m    177\u001b[0m \u001b[39mreturn\u001b[39;00m run\n","File \u001b[0;32m~/miniconda3/envs/main/lib/python3.10/site-packages/mlflow/store/tracking/rest_store.py:56\u001b[0m, in \u001b[0;36mRestStore._call_endpoint\u001b[0;34m(self, api, json_body)\u001b[0m\n\u001b[1;32m     54\u001b[0m endpoint, method \u001b[39m=\u001b[39m _METHOD_TO_INFO[api]\n\u001b[1;32m     55\u001b[0m response_proto \u001b[39m=\u001b[39m api\u001b[39m.\u001b[39mResponse()\n\u001b[0;32m---> 56\u001b[0m \u001b[39mreturn\u001b[39;00m call_endpoint(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_host_creds(), endpoint, method, json_body, response_proto)\n","File \u001b[0;32m~/miniconda3/envs/main/lib/python3.10/site-packages/mlflow/utils/rest_utils.py:287\u001b[0m, in \u001b[0;36mcall_endpoint\u001b[0;34m(host_creds, endpoint, method, json_body, response_proto)\u001b[0m\n\u001b[1;32m    283\u001b[0m     response \u001b[39m=\u001b[39m http_request(\n\u001b[1;32m    284\u001b[0m         host_creds\u001b[39m=\u001b[39mhost_creds, endpoint\u001b[39m=\u001b[39mendpoint, method\u001b[39m=\u001b[39mmethod, params\u001b[39m=\u001b[39mjson_body\n\u001b[1;32m    285\u001b[0m     )\n\u001b[1;32m    286\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 287\u001b[0m     response \u001b[39m=\u001b[39m http_request(\n\u001b[1;32m    288\u001b[0m         host_creds\u001b[39m=\u001b[39;49mhost_creds, endpoint\u001b[39m=\u001b[39;49mendpoint, method\u001b[39m=\u001b[39;49mmethod, json\u001b[39m=\u001b[39;49mjson_body\n\u001b[1;32m    289\u001b[0m     )\n\u001b[1;32m    290\u001b[0m response \u001b[39m=\u001b[39m verify_rest_response(response, endpoint)\n\u001b[1;32m    291\u001b[0m js_dict \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(response\u001b[39m.\u001b[39mtext)\n","File \u001b[0;32m~/miniconda3/envs/main/lib/python3.10/site-packages/mlflow/utils/rest_utils.py:192\u001b[0m, in \u001b[0;36mhttp_request\u001b[0;34m(host_creds, endpoint, method, max_retries, backoff_factor, extra_headers, retry_codes, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[39mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    187\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAPI request to \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m failed with timeout exception \u001b[39m\u001b[39m{\u001b[39;00mto\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m To increase the timeout, set the environment variable \u001b[39m\u001b[39m{\u001b[39;00mMLFLOW_HTTP_REQUEST_TIMEOUT\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    189\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m to a larger value.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m     )\n\u001b[1;32m    191\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 192\u001b[0m     \u001b[39mraise\u001b[39;00m MlflowException(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAPI request to \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m failed with exception \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n","\u001b[0;31mMlflowException\u001b[0m: API request to http://127.0.0.1:5000/api/2.0/mlflow/runs/create failed with exception HTTPConnectionPool(host='127.0.0.1', port=5000): Max retries exceeded with url: /api/2.0/mlflow/runs/create (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa66bd76680>: Failed to establish a new connection: [Errno 111] Connection refused'))"]}],"source":["counter = 1\n","for Model_Name, classifier in Models.items(): \n","    # with mlflow.start_run(nested=True):\n","    print(f\"{counter}. {Model_Name}\")\n","    \n","    with mlflow.start_run():\n","        # fit the model\n","        from joblib import parallel_backend\n","        with parallel_backend('threading', n_jobs=-1):\n","            classifier.fit(train_feature, train_label)\n","        counter = counter + 1\n","        \n","        # Calculate the metrics\n","        base_score,accuracy,av_precision = eval_metrics(classifier,\n","                                                        valid_feature,\n","                                                        valid_label)  \n","        \n","        mlflow.log_param(\"Model\"           , Model_Name)\n","        mlflow.log_param(\"Dataset\" , \"Mix\")\n","        mlflow.log_metric(\"base_score\"     , base_score)\n","        mlflow.log_metric(\"accuracy\"       , accuracy)\n","        mlflow.log_metric(\"av_precision\"   , av_precision)\n","        \n","        if av_precision > 0.95 :\n","            mlflow.sklearn.log_model(classifier,Model_Name, signature=signature)\n","            print(f\"f1 socre is more than 0.945 so the {Model_Name} is saved\")\n","        else :\n","            print(f\"Because f1 socre is not quality. The model is skip to saving phase.\")\n","        \n","        print(\"________________________________________\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import layers\n","from tensorflow import keras\n","from datetime import datetime"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# LSTM Model\n","# epoch = 20\n","# input_shape = 3\n","\n","# inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n","# x = layers.Lambda(lambda x: tf.expand_dims(x, axis=-1))(inputs)\n","# x = layers.LSTM(64)(x) # return vector for whole sequence\n","# x = layers.Dense(16, activation=\"relu\")(x) \n","# outputs = layers.Dense(4, activation=\"softmax\")(x)\n","# model = tf.keras.Model(inputs, outputs, name=\"model_LSTM\")\n","\n","\n","\n","# model.compile(loss=\"categorical_crossentropy\",\n","#               optimizer=tf.keras.optimizers.Adam(),\n","#               metrics=[\"accuracy\"])\n","\n","# model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # Callbacks\n","# early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", # watch the val loss metric\n","#                                                   patience=5) # if val loss decreases for 3 epochs in a row, stop training\n","\n","# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",  \n","#                                                  factor=0.2, # multiply the learning rate by 0.2 (reduce by 5x)\n","#                                                  patience=3,\n","#                                                  verbose=1, # print out when learning rate goes down \n","#                                                  min_lr=1e-7)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# train_dataset = tf.data.Dataset.from_tensor_slices((train_feature, train_label))\n","# train_dataset =  train_dataset.batch(2048).prefetch(tf.data.AUTOTUNE)\n","\n","# valid_dataset = tf.data.Dataset.from_tensor_slices((valid_feature, valid_label))\n","# valid_dataset = valid_dataset.batch(2048).prefetch(tf.data.AUTOTUNE)\n","\n","# test_dataset = tf.data.Dataset.from_tensor_slices((test_feature,test_label))\n","# test_dataset = test_dataset.batch(2048).prefetch(tf.data.AUTOTUNE)\n","\n","# train_dataset, valid_dataset, test_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # fit the model\n","# start = datetime.now()\n","# with mlflow.start_run():\n","#     mlflow.tensorflow.autolog()\n","    \n","#     # fit the model\n","#     # with tf.device('/GPU:0'):\n","#     start = datetime.now()\n","#     history_model = model.fit(train_dataset,\n","#                             batch_size=2048,\n","#                             steps_per_epoch=len(train_dataset),\n","#                             validation_data=valid_dataset,\n","#                             validation_steps=int(len(valid_dataset)),\n","#                             callbacks=[early_stopping, reduce_lr],\n","#                             epochs=epoch) \n","#     end = datetime.now()\n","#     print(f\"The time taken to train the model is {end - start}\")\n","        \n","#     # Evaluate model\n","#     model.evaluate(test_dataset)\n","    \n","#     # Calculate the metrics\n","#     # model_results = eval_metrics(model, \n","#     #                              test_features = test_feature,\n","#     #                              test_labels = test_label)\n","    \n","#     mlflow.log_param(\"Model\"   , \"LSTM\")\n","#     mlflow.log_param(\"Dataset\" , \"Mix\")\n","#     # mlflow.log_params(model_results)\n","#     mlflow.tensorflow.autolog()\n","\n","# print(\"________________________________________\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # Calculate the metrics\n","# model_preds_probs   = model.predict(test_feature)\n","# av_precision    = average_precision_score(test_label, model_preds_probs)\n","# av_precision"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # Build the model \n","# input_shape = 3\n","\n","# inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n","# x = layers.Dense(32, activation ='relu')(inputs)\n","# x = layers.Dense(64, activation = 'relu')(x)\n","# # x = layers.BatchNormalization()(x)\n","# # x = layers.Dropout(0.1)(x)\n","# # x = layers.Dense(128, activation ='relu')(x)\n","# # x = layers.Dense(512, activation = 'relu')(x)\n","# # x = layers.BatchNormalization()(x)\n","# # x = layers.Dropout(0.25)(x)\n","# # x = layers.Dense(1024, activation ='relu')(x)\n","# # x = layers.Dense(512, activation = 'relu')(x)\n","# # x = layers.BatchNormalization()(x)\n","# # x = layers.Dropout(0.5)(x)\n","# # x = layers.Dense(128, activation=\"relu\")(x)\n","# # x = layers.Dense(64, activation=\"relu\")(x)\n","# x = layers.Dense(32, activation=\"relu\")(x)\n","# outputs = layers.Dense(4, activation=\"softmax\",name=\"output_layer\")(x)      \n","# model_DNN = tf.keras.Model(inputs, outputs) \n","\n","# model_DNN.compile(loss=\"categorical_crossentropy\",\n","#               optimizer=tf.keras.optimizers.Adam(),\n","#               metrics=[\"accuracy\"])\n","\n","# model_DNN.summary()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# from sklearn.model_selection import cross_val_score\n","# counter = 1\n","# Model_Name = 'DNN_model'\n","# import os\n","# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","# tf.get_logger().setLevel('ERROR')\n","# tf.autograph.set_verbosity(1)\n","# tf.set_seed = 42\n","# np.random.seed(40)\n","\n","# with mlflow.start_run():\n","#     mlflow.tensorflow.autolog()\n","    \n","#     # fit the model\n","#     # with tf.device('/GPU:0'):\n","#     start = datetime.now()\n","#     history_model = model_DNN.fit(train_dataset,\n","#                                   batch_size=2048,\n","#                                   steps_per_epoch=len(train_dataset),\n","#                                   validation_data=valid_dataset,\n","#                                   validation_steps=int(len(valid_dataset)),\n","#                                   callbacks=[early_stopping, reduce_lr],\n","#                                   epochs=epoch) \n","#     end = datetime.now()\n","#     print(f\"The time taken to train the model is {end - start}\")\n","        \n","#     # Evaluate model\n","#     model_DNN.evaluate(test_dataset)\n","    \n","#     # Calculate the metrics\n","#     # model_results = eval_metrics(model, \n","#     #                              test_features = test_feature,\n","#     #                              test_labels = test_label)\n","    \n","#     mlflow.log_param(\"Model\"           , Model_Name)\n","#     mlflow.log_param(\"Dataset\" , \"Mix\")\n","#     # mlflow.log_params(model_results)\n","#     mlflow.tensorflow.autolog()\n","    \n","    \n","#     print(\"________________________________________\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # Calculate the metrics\n","# model_preds_probs   = model_DNN.predict(test_feature)\n","# av_precision    = average_precision_score(test_label, model_preds_probs)\n","# print(av_precision)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Final test"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# import os \n","# import pandas as pd\n","\n","# def import_test_file_from_folder(file_path):\n","#     test_file = pd.read_csv(file_path)\n","#     name = os.path.basename(file_path)\n","#     id_value = name.split('.')[0]\n","#     test_file['Id_value'] = id_value\n","#     test_file['Id'] = test_file['Id_value'].astype(str) + '_' + test_file['Time'].astype(str)\n","#     test_file = test_file[['Id','AccV','AccML','AccAP']]\n","#     return test_file\n","\n","# def preprocessing_test_dataset(df):\n","#     import random \n","#     random_seed = 54\n","    \n","#     feature_col = ['AccV','AccML','AccAP']\n","#     feature_dataset = df[feature_col]\n","\n","#     feature_dataset=np.array(feature_dataset)\n","#     return feature_dataset\n","\n","# def make_prediction(Models, test_submit):\n","#     for Model_Name, classifier in Models.items(): \n","#         test_submit_pred = classifier.predict(test_submit)\n","#     print(f\"The prediciton is {test_submit_pred.shape}\")\n","#     return test_submit_pred\n","\n","# def test_submission_file(test_file, predicit_score_np):\n","#     test_score_df = pd.DataFrame(predicit_score_np, columns=['StartHesitation', 'Turn', 'Walking', 'All_zero'])\n","#     df = pd.concat([test_file, test_score_df], ignore_index= False, sort=False, axis=1)\n","#     select_column = ['Id','StartHesitation', 'Turn', 'Walking']\n","#     submit_dataset = df[select_column]\n","#     return submit_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# test_file_path = ('/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/test')\n","# test_defog_path = testfile_path+'defog/02ab235146.csv'\n","# test_tdcsfog_path = test_file_path+'tdcsfog/003f117e14.csv'"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# test_defog = import_test_file_from_folder(test_defog_path)\n","# test_tdcsfog = import_test_file_from_folder(test_tdcsfog_path)\n","\n","# test_df =  pd.concat([test_tdcsfog, test_defog])\n","# print(test_df.head(), test_df.shape)\n","# test_submit = preprocessing_test_dataset(test_df)\n","# print(test_submit.head())\n","# test_submit_pred = make_prediction(Models, test_submit)\n","# test_submission_file = test_submission_file(test_df, test_submit_pred)\n","# print(test_submission_file.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# test_submission_file.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# submission_sample = pd.read_csv('/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/sample_submission.csv')\n","# submission_sample.shape == test_submission_file.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# test_submission_file.to_csv('submission.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":4}
