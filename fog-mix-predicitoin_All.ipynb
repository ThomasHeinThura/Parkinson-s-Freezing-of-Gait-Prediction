{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T10:43:38.737126Z","iopub.status.busy":"2023-05-09T10:43:38.736584Z","iopub.status.idle":"2023-05-09T10:43:38.743491Z","shell.execute_reply":"2023-05-09T10:43:38.741928Z","shell.execute_reply.started":"2023-05-09T10:43:38.737055Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np \n","import matplotlib.pyplot as plt\n","import os\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Import with ID"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T10:43:38.745755Z","iopub.status.busy":"2023-05-09T10:43:38.745258Z","iopub.status.idle":"2023-05-09T10:43:38.765496Z","shell.execute_reply":"2023-05-09T10:43:38.764307Z","shell.execute_reply.started":"2023-05-09T10:43:38.745714Z"},"trusted":true},"outputs":[],"source":["# def preprocess_the_whole_stage(folder_path):\n","#     # create an empty list to store the DataFrames\n","#     dfs = []\n","\n","#     # loop over all files in the folder\n","#     for filename in os.listdir(folder_path):\n","#         if filename.endswith(\".csv\"):\n","#             # extract the ID from the filename (assuming the filename is in the format \"ID.csv\")\n","#             file_id = os.path.splitext(filename)[0]\n","\n","#             # read the CSV file into a DataFrame and add the ID as a new column\n","#             df = pd.read_csv(os.path.join(folder_path, filename))\n","#             df.insert(0, 'ID', file_id)\n","\n","#             # append the DataFrame to the list\n","#             dfs.append(df)\n","\n","#     # concatenate all DataFrames into a single DataFrame\n","#     full_dataset = pd.concat(dfs)\n","    \n","#     # print the resulting DataFrame\n","#     print(full_dataset.head())\n","    \n","#     # Add all zero class\n","#     condition = (full_dataset.StartHesitation == 0) & (full_dataset.Turn == 0) & (full_dataset.Walking == 0)\n","#     condition_2 = (full_dataset.StartHesitation == 1) | (full_dataset.Turn == 1) | (full_dataset.Walking == 1)\n","    \n","#     full_dataset.loc[condition, 'All_zero'] = 1\n","#     full_dataset.loc[condition_2, 'All_zero'] = 0\n","#     print(full_dataset.head())\n","    \n","#     print(\"Cleaning the Dataset\")\n","#     if 'Valid' in full_dataset.columns:\n","#         remove_col = ['ID','Time', 'Valid', 'Task']\n","        \n","#     else:\n","#         remove_col = ['ID','Time']\n","#     print(f\"The remove columns : {remove_col}\")\n","#     clean_dataset = full_dataset.drop(full_dataset[remove_col],axis=1)\n","#     print(clean_dataset.head())\n","    \n","#     # search duplication\n","#     print(f\"Search for Duplication : {clean_dataset.duplicated().sum()}\")\n","#     clean_dataset.drop_duplicates(inplace=True)\n","#     print(f\"Search for Duplication : {clean_dataset.duplicated().sum()}\")\n","#     print(clean_dataset.head())\n","    \n","#     print(\"Checking conditon\")\n","#     condition = (clean_dataset.StartHesitation == 0) & (clean_dataset.Turn == 0 ) & (clean_dataset.Walking == 0)\n","#     total_zero = clean_dataset[condition].shape[0]\n","#     print(f\"Total number where three class are zero: {total_zero}\")\n","#     All_zero = clean_dataset[clean_dataset.All_zero == 1].shape[0]\n","#     print(f\"Total number of All_zero class: {All_zero}\")\n","#     print(f\"Is all zero and Total number zero are equal :{All_zero == total_zero}\")\n","#     a = clean_dataset[clean_dataset.StartHesitation == 1].shape[0]\n","#     print(f\"The number of Class Start Hesitation :{a}\")\n","#     b = clean_dataset[clean_dataset.Walking == 1].shape[0]\n","#     print(f\"The number of Class Walking :{b}\")\n","#     c = clean_dataset[clean_dataset.Turn == 1].shape[0]\n","#     print(f\"The number of Class Turn : {c}\")\n","#     print(f\"Is the toatl number of sample equal to all Four class combine :\"\n","#          f\"{clean_dataset.shape[0] == a + b + c + All_zero}\")\n","    \n","#     return clean_dataset\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T10:43:38.770901Z","iopub.status.busy":"2023-05-09T10:43:38.770314Z","iopub.status.idle":"2023-05-09T10:43:38.784366Z","shell.execute_reply":"2023-05-09T10:43:38.783293Z","shell.execute_reply.started":"2023-05-09T10:43:38.770852Z"},"trusted":true},"outputs":[],"source":["# def oversampling_and_split(clean_dataset):\n","#     feature_col = ['AccV','AccML','AccAP']\n","#     label_col = ['StartHesitation','Turn','Walking', 'All_zero']\n","\n","#     feature_dataset = clean_dataset[feature_col]\n","#     label_dataset = clean_dataset[label_col]\n","#     print(f\"The Feature :{feature_dataset.shape}, \\n\"\n","#           f\"The label {label_dataset.shape}\")\n","    \n","#     print(f\"Because of Four Classes are imbalanced. To get high accuracy, oversampling is used\")\n","#     from imblearn.over_sampling import SMOTE\n","#     import numpy as np\n","#     # Instantiate the MultiLabelUnderSampler\n","#     over_sampler = SMOTE()\n","\n","#     # Undersample the dataset\n","#     X_resampled, y_resampled = over_sampler.fit_resample(feature_dataset.to_numpy(), label_dataset.to_numpy())\n","    \n","#     SMOTE_features_dataset = pd.DataFrame(X_resampled, columns=feature_dataset.columns)\n","    \n","    \n","#     SMOTE_labels_dataset = pd.DataFrame(y_resampled, columns=label_dataset.columns)\n","#     print(f\"The over sampling label shape : {SMOTE_labels_dataset.shape}\")\n","    \n","#     def check_all_four_class_condition(df):\n","#         print(f\"Check all four check condiiton in {df}\")\n","#         a = df[df.StartHesitation == 1].shape[0]\n","#         b = df[df.Turn == 1].shape[0]\n","#         c = df[df.Walking ==1].shape[0]\n","#         d = df[df.All_zero == 1].shape[0]\n","#         print(f\"Number of Start Hesitation : {a}, \\n\"\n","#               f\"Number of Turn : {b}, \\n\"  \n","#               f\"Number of Walking : {c}, \\n\"\n","#               f\"Number of All_zero : {d}\")\n","#         print(\"Is Number of All four class is equal to total sampling :\",\n","#              df.shape[0] == a + b + c + d)\n","        \n","#     check_all_four_class_condition(SMOTE_labels_dataset)\n","    \n","#     oversampling_dataset = pd.concat([SMOTE_features_dataset,SMOTE_labels_dataset], \n","#                                      ignore_index= False, sort=False, axis=1)\n","#     print(f\"The shape of oversampling dataset is : {oversampling_dataset.shape[0]}\")\n","#     print(f\"The number of duplication in dataset : {oversampling_dataset.duplicated().sum()}\")\n","#     # Drop duplication\n","#     oversampling_dataset.drop_duplicates(inplace=True)\n","#     print(f\"The shape of oversampling after remove duplication :{oversampling_dataset.shape}\")\n","    \n","#     # 60% Train Data, 20% Validation Data, 20% Test Data\n","#     # 80% Set Data(60% rain Data, 20% Validation Data) , 20% Test Data\n","    \n","#     from sklearn.model_selection import train_test_split\n","#     import random \n","#     random_seed = 54\n","\n","#     set_data, test_data = train_test_split(oversampling_dataset, test_size=0.2, random_state=True)\n","#     print(f\"The set data shape : {set_data.shape}\\n\"\n","#           f\"The test data shape : {test_data.shape}\\n\"\n","#           f\"Is the dataset still in range : \"\n","#           f\"{oversampling_dataset.shape[0] == set_data.shape[0] + test_data.shape[0]}\")\n","    \n","#     print(f\"Again Search for duplicaiton : \\n \"\n","#           f\"Set Data :{set_data.duplicated().sum()} \\n\"\n","#           f\"Test Data :{test_data.duplicated().sum()}\")\n","    \n","#     check_all_four_class_condition(set_data)\n","#     check_all_four_class_condition(test_data)\n","#     print(\"All task are finish\")\n","    \n","#     return set_data, test_data\n","    "]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T10:43:38.926021Z","iopub.status.busy":"2023-05-09T10:43:38.924800Z","iopub.status.idle":"2023-05-09T10:43:38.934262Z","shell.execute_reply":"2023-05-09T10:43:38.932862Z","shell.execute_reply.started":"2023-05-09T10:43:38.925960Z"},"trusted":true},"outputs":[],"source":["# def preprocessing_the_dataset(df):\n","# #     def check_skewness(df):\n","# #     # this can check relation between each column\n","# #         skew_limit=0.75\n","# #         skew_value=df[df.columns].skew()\n","# #         #print(skew_value)\n","# #         skew_col=skew_value[abs(skew_value)>skew_limit]\n","# #         cols=skew_col.index\n","# #         return cols\n","\n","#     import random \n","#     random_seed = 54\n","    \n","#     feature_col = ['AccV','AccML','AccAP']\n","#     label_col = ['StartHesitation','Turn','Walking', 'All_zero']\n","\n","#     # make feature and label\n","#     feature_dataset = df[feature_col]\n","#     label_dataset = df[label_col]\n","    \n","# #     # check skewness and powertransform\n","# #     skew_columns = check_skewness(feature_dataset)\n","# #     print(skew_columns)\n","    \n","# #     print(\"Power Transform start\")\n","# #     from sklearn.preprocessing import PowerTransformer\n","# #     pt=PowerTransformer(standardize=False)  \n","# #     feature_dataset[skew_columns] = pt.fit_transform(feature_dataset[skew_columns])\n","    \n","# #     print(\"Standardization start\")\n","# #     # Change features data to 0 and 1\n","# #     from sklearn.preprocessing import StandardScaler\n","# #     sc=StandardScaler()\n","# #     feature_dataset=sc.fit_transform(feature_dataset)\n","    \n","#     print(\"Train test split begin\")\n","#     from sklearn.model_selection import train_test_split\n","#     train_feature, valid_feature, train_label, valid_label = train_test_split(feature_dataset, label_dataset, test_size=0.2, random_state=True)\n","    \n","#     train_feature = np.array(train_feature) \n","#     valid_feature = np.array(valid_feature)\n","#     train_label  = np.array(train_label)\n","#     valid_label = np.array(valid_label)\n","#     print(\"All task are finish\")\n","    \n","#     return train_feature, valid_feature, train_label, valid_label\n","    "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Import Defog Dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-05-09T10:43:38.937635Z","iopub.status.busy":"2023-05-09T10:43:38.937051Z","iopub.status.idle":"2023-05-09T10:45:42.854023Z","shell.execute_reply":"2023-05-09T10:45:42.852833Z","shell.execute_reply.started":"2023-05-09T10:43:38.937568Z"},"trusted":true},"outputs":[],"source":["# # specify the folder path\n","# defog_path = \"Data/train/defog\"\n","# clean_defog_dataset = preprocess_the_whole_stage(defog_path)\n","# tdcsfog_path = \"Data/train/tdcsfog\"\n","# clean_tdcsfog_dataset= preprocess_the_whole_stage(tdcsfog_path)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Mix two dataset and oversplit"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T10:45:42.856248Z","iopub.status.busy":"2023-05-09T10:45:42.855803Z","iopub.status.idle":"2023-05-09T10:45:42.880747Z","shell.execute_reply":"2023-05-09T10:45:42.879456Z","shell.execute_reply.started":"2023-05-09T10:45:42.856206Z"},"trusted":true},"outputs":[],"source":["# clean_defog_dataset.head()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T10:45:42.882767Z","iopub.status.busy":"2023-05-09T10:45:42.882323Z","iopub.status.idle":"2023-05-09T10:45:42.901115Z","shell.execute_reply":"2023-05-09T10:45:42.899798Z","shell.execute_reply.started":"2023-05-09T10:45:42.882726Z"},"trusted":true},"outputs":[],"source":["# clean_tdcsfog_dataset.head()"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T10:45:42.904310Z","iopub.status.busy":"2023-05-09T10:45:42.903890Z","iopub.status.idle":"2023-05-09T10:45:43.487819Z","shell.execute_reply":"2023-05-09T10:45:43.486504Z","shell.execute_reply.started":"2023-05-09T10:45:42.904278Z"},"trusted":true},"outputs":[],"source":["# clean_dataset = pd.concat([clean_tdcsfog_dataset, clean_defog_dataset ], \n","#                            ignore_index= True, sort=False, axis=0)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T10:45:43.489797Z","iopub.status.busy":"2023-05-09T10:45:43.489460Z","iopub.status.idle":"2023-05-09T10:45:43.496557Z","shell.execute_reply":"2023-05-09T10:45:43.495486Z","shell.execute_reply.started":"2023-05-09T10:45:43.489768Z"},"trusted":true},"outputs":[],"source":["# clean_dataset.shape"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T10:45:43.498440Z","iopub.status.busy":"2023-05-09T10:45:43.498085Z","iopub.status.idle":"2023-05-09T10:45:43.515613Z","shell.execute_reply":"2023-05-09T10:45:43.514349Z","shell.execute_reply.started":"2023-05-09T10:45:43.498412Z"},"trusted":true},"outputs":[],"source":["# clean_dataset.head()"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T10:45:43.518084Z","iopub.status.busy":"2023-05-09T10:45:43.517032Z","iopub.status.idle":"2023-05-09T10:54:41.255872Z","shell.execute_reply":"2023-05-09T10:54:41.253714Z","shell.execute_reply.started":"2023-05-09T10:45:43.518030Z"},"trusted":true},"outputs":[],"source":["# set_data,test_data = oversampling_and_split(clean_dataset)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T10:54:41.258539Z","iopub.status.busy":"2023-05-09T10:54:41.258151Z","iopub.status.idle":"2023-05-09T10:54:56.708707Z","shell.execute_reply":"2023-05-09T10:54:56.707285Z","shell.execute_reply.started":"2023-05-09T10:54:41.258503Z"},"trusted":true},"outputs":[],"source":["# train_feature, valid_feature, train_label, valid_label = preprocessing_the_dataset(set_data)\n","# print(f\"{train_feature.shape} , {train_label.shape} , {valid_feature.shape} , {valid_label.shape}, {test_data.shape}\")"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# def preprocessing_test_dataset(df):\n","\n","#     import random \n","#     random_seed = 54\n","    \n","#     feature_col = ['AccV','AccML','AccAP']\n","#     label_col = ['StartHesitation','Turn','Walking', 'All_zero']\n","\n","#     # make feature and label\n","#     feature_dataset = df[feature_col]\n","#     label_dataset = df[label_col]\n","    \n","#     feature_dataset = np.array(feature_dataset) \n","#     label_dataset  = np.array(label_dataset)\n","#     print(\"All task are finish\")\n","    \n","#     return feature_dataset, label_dataset"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# test_feature, test_label = preprocessing_test_dataset(test_data)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["# test_feature.shape, test_label.shape"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# np.save('Data/mix/train_feature.npy',train_feature) \n","# np.save('Data/mix/valid_feature.npy', valid_feature)\n","# np.save('Data/mix/train_label.npy', train_label)\n","# np.save('Data/mix/valid_label.npy',valid_label)\n","# np.save('Data/mix/test_feature.npy',test_feature)\n","# np.save('Data/mix/test_label.npy',test_label)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["load_data_path = 'Nearmiss'"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Build Model"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T10:54:56.710486Z","iopub.status.busy":"2023-05-09T10:54:56.710154Z","iopub.status.idle":"2023-05-09T10:54:56.719769Z","shell.execute_reply":"2023-05-09T10:54:56.718394Z","shell.execute_reply.started":"2023-05-09T10:54:56.710459Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import accuracy_score\n","from sklearn.metrics import balanced_accuracy_score\n","from sklearn.metrics import average_precision_score\n","from sklearn.metrics import classification_report\n","\n","def eval_metrics(classifier, test_features, test_labels):\n","    \n","    # make prediction\n","    predictions   = classifier.predict(test_features)\n","    \n","    base_score   = classifier.score(test_features, test_labels)\n","    accuracy = accuracy_score(test_labels, predictions)\n","    av_precision = average_precision_score(test_labels, predictions)\n","    \n","    target_names = ['StartHesitation','Turn','Walking', 'All_zero']\n","    print(\"Classification report\")\n","    print(\"---------------------\",\"\\n\")\n","    print(classification_report(test_labels, predictions, target_names=target_names),\"\\n\")\n","\n","    print(\"Accuracy Measures\")\n","    print(\"---------------------\",\"\\n\")\n","    print(\"Base score: \", base_score)\n","    print(\"Accuracy: \", accuracy)\n","    print(\"Avarge Precision: \", av_precision)\n","    \n","    return base_score,accuracy,av_precision"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-05-09T10:54:56.721656Z","iopub.status.busy":"2023-05-09T10:54:56.721306Z","iopub.status.idle":"2023-05-09T10:54:56.732603Z","shell.execute_reply":"2023-05-09T10:54:56.731199Z","shell.execute_reply.started":"2023-05-09T10:54:56.721628Z"},"trusted":true},"outputs":[],"source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import ExtraTreesClassifier\n","import xgboost as xgb\n","\n","Models = { \n","    \"Decision Tree\": DecisionTreeClassifier(),      \n","    \"KNearest\": KNeighborsClassifier(n_jobs=-1),   \n","    \"XGB\" : xgb.XGBClassifier(tree_method='gpu_hist', gpu_id=0,\n","                            #   max_depth=10, n_estimators=20, learning_rate=0.05\n","                              ), \n","    # \"Extra_T\" : ExtraTreesClassifier(n_estimators=50),\n","    # \"R_forest\" : RandomForestClassifier(n_estimators=50),       \n","}"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tracking URI: 'http://127.0.0.1:5000'\n"]}],"source":["import mlflow\n","import mlflow.tensorflow\n","mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n","print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\")"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1. Decision Tree\n","Classification report\n","--------------------- \n","\n","                 precision    recall  f1-score   support\n","\n","StartHesitation       0.65      0.64      0.65     49155\n","           Turn       0.62      0.62      0.62     48680\n","        Walking       0.90      0.90      0.90     48603\n","       All_zero       0.65      0.64      0.64     48948\n","\n","      micro avg       0.70      0.70      0.70    195386\n","      macro avg       0.70      0.70      0.70    195386\n","   weighted avg       0.70      0.70      0.70    195386\n","    samples avg       0.70      0.70      0.70    195386\n"," \n","\n","Accuracy Measures\n","--------------------- \n","\n","Base score:  0.7031926545402434\n","Accuracy:  0.7031926545402434\n","Avarge Precision:  0.5820932419805591\n","Because f1 socre is not quality. The model is skip to saving phase.\n","________________________________________\n","2. KNearest\n","Classification report\n","--------------------- \n","\n","                 precision    recall  f1-score   support\n","\n","StartHesitation       0.64      0.38      0.48     49155\n","           Turn       0.58      0.42      0.49     48680\n","        Walking       0.94      0.82      0.88     48603\n","       All_zero       0.55      0.65      0.60     48948\n","\n","      micro avg       0.67      0.57      0.61    195386\n","      macro avg       0.68      0.57      0.61    195386\n","   weighted avg       0.68      0.57      0.61    195386\n","    samples avg       0.57      0.57      0.57    195386\n"," \n","\n","Accuracy Measures\n","--------------------- \n","\n","Base score:  0.5652759153675289\n","Accuracy:  0.5652759153675289\n","Avarge Precision:  0.5117676903691396\n"]},{"name":"stderr","output_type":"stream","text":["/home/hanlinn/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Because f1 socre is not quality. The model is skip to saving phase.\n","________________________________________\n","3. XGB\n","Classification report\n","--------------------- \n","\n","                 precision    recall  f1-score   support\n","\n","StartHesitation       0.75      0.53      0.62     49155\n","           Turn       0.69      0.49      0.57     48680\n","        Walking       0.95      0.85      0.90     48603\n","       All_zero       0.66      0.66      0.66     48948\n","\n","      micro avg       0.76      0.63      0.69    195386\n","      macro avg       0.76      0.63      0.69    195386\n","   weighted avg       0.76      0.63      0.69    195386\n","    samples avg       0.63      0.63      0.63    195386\n"," \n","\n","Accuracy Measures\n","--------------------- \n","\n","Base score:  0.6249065951501132\n","Accuracy:  0.6249065951501132\n","Avarge Precision:  0.5867750282480048\n","Because f1 socre is not quality. The model is skip to saving phase.\n","________________________________________\n"]},{"name":"stderr","output_type":"stream","text":["/home/hanlinn/.local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["counter = 1\n","for Model_Name, classifier in Models.items(): \n","    # with mlflow.start_run(nested=True):\n","    print(f\"{counter}. {Model_Name}\")\n","    \n","    with mlflow.start_run():\n","        # fit the model\n","        from joblib import parallel_backend\n","        with parallel_backend('threading', n_jobs=-1):\n","            classifier.fit(train_feature, train_label)\n","        counter = counter + 1\n","        \n","        # Calculate the metrics\n","        base_score,accuracy,av_precision = eval_metrics(classifier,\n","                                                        valid_feature,\n","                                                        valid_label)  \n","        \n","        mlflow.log_param(\"Model\"           , Model_Name)\n","        mlflow.log_param(\"Dataset\" , f'{load_data_path}')\n","        mlflow.log_metric(\"base_score\"     , base_score)\n","        mlflow.log_metric(\"accuracy\"       , accuracy)\n","        mlflow.log_metric(\"av_precision\"   , av_precision)\n","        \n","        if av_precision > 0.95 :\n","            # mlflow.sklearn.log_model(classifier,Model_Name, signature=signature)\n","            print(f\"f1 socre is more than 0.945 so the {Model_Name} is saved\")\n","        else :\n","            print(f\"Because f1 socre is not quality. The model is skip to saving phase.\")\n","        \n","        print(\"________________________________________\")"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-05-11 11:21:47.919487: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras import layers\n","from tensorflow import keras\n","from datetime import datetime"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-05-11 11:21:49.310495: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-11 11:21:49.328842: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-11 11:21:49.329070: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-11 11:21:49.331138: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-11 11:21:49.331339: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-11 11:21:49.331471: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-11 11:21:49.834561: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-11 11:21:49.834743: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-11 11:21:49.834884: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-05-11 11:21:49.834996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 333 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:0a:00.0, compute capability: 8.6\n","2023-05-11 11:21:49.835252: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n","2023-05-11 11:21:50.033327: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n","\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n","2023-05-11 11:21:50.034441: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n","\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n","2023-05-11 11:21:50.035362: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n","\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n","2023-05-11 11:21:50.156104: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n","\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n","2023-05-11 11:21:50.194545: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n","\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n","2023-05-11 11:21:50.195642: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n","\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n","2023-05-11 11:21:50.196554: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n","\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n","2023-05-11 11:21:50.370857: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n","\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n","2023-05-11 11:21:50.372172: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n","\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n","2023-05-11 11:21:50.373097: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n","\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n","2023-05-11 11:21:50.489786: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n","\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n","2023-05-11 11:21:50.528397: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n","\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n","2023-05-11 11:21:50.529455: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n","\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n","2023-05-11 11:21:50.530391: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n","\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"]},{"name":"stdout","output_type":"stream","text":["Model: \"model_LSTM\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_layer (InputLayer)    [(None, 4)]               0         \n","                                                                 \n"," lambda (Lambda)             (None, 4, 1)              0         \n","                                                                 \n"," bidirectional (Bidirectiona  (None, 4, 128)           33792     \n"," l)                                                              \n","                                                                 \n"," bidirectional_1 (Bidirectio  (None, 128)              98816     \n"," nal)                                                            \n","                                                                 \n"," dense (Dense)               (None, 32)                4128      \n","                                                                 \n"," dense_1 (Dense)             (None, 16)                528       \n","                                                                 \n"," dense_2 (Dense)             (None, 4)                 68        \n","                                                                 \n","=================================================================\n","Total params: 137,332\n","Trainable params: 137,332\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["epoch = 5\n","input_shape = 4\n","\n","inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n","x = layers.Lambda(lambda x: tf.expand_dims(x, axis=-1))(inputs)\n","x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x) # stacking RNN layers requires return_sequences=True\n","x = layers.Bidirectional(layers.LSTM(64))(x)\n","x = layers.Dense(32, activation=\"relu\")(x) \n","x = layers.Dense(16, activation=\"relu\")(x) \n","outputs = layers.Dense(4, activation=\"softmax\")(x)\n","model = tf.keras.Model(inputs, outputs, name=\"model_LSTM\")\n","\n","\n","\n","model.compile(loss=\"categorical_crossentropy\",\n","              optimizer=tf.keras.optimizers.Adam(),\n","              metrics=[\"accuracy\"])\n","\n","model.summary()"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["# Callbacks\n","early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", # watch the val loss metric\n","                                                  patience=5) # if val loss decreases for 3 epochs in a row, stop training\n","\n","reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",  \n","                                                 factor=0.2, # multiply the learning rate by 0.2 (reduce by 5x)\n","                                                 patience=3,\n","                                                 verbose=1, # print out when learning rate goes down \n","                                                 min_lr=1e-7)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/plain":["(<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 4), dtype=tf.float64, name=None), TensorSpec(shape=(None, 4), dtype=tf.int64, name=None))>,\n"," <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 4), dtype=tf.float64, name=None), TensorSpec(shape=(None, 4), dtype=tf.int64, name=None))>,\n"," <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 4), dtype=tf.float64, name=None), TensorSpec(shape=(None, 4), dtype=tf.int64, name=None))>)"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset = tf.data.Dataset.from_tensor_slices((train_feature, train_label))\n","train_dataset =  train_dataset.batch(2048).prefetch(tf.data.AUTOTUNE)\n","\n","valid_dataset = tf.data.Dataset.from_tensor_slices((valid_feature, valid_label))\n","valid_dataset = valid_dataset.batch(2048).prefetch(tf.data.AUTOTUNE)\n","\n","test_dataset = tf.data.Dataset.from_tensor_slices((test_feature,test_label))\n","test_dataset = test_dataset.batch(2048).prefetch(tf.data.AUTOTUNE)\n","\n","train_dataset, valid_dataset, test_dataset"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n"]},{"name":"stderr","output_type":"stream","text":["2023-05-11 11:21:51.134697: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [781542,4]\n","\t [[{{node Placeholder/_1}}]]\n","2023-05-11 11:21:51.358006: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n","\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n","2023-05-11 11:21:51.359613: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n","\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n","2023-05-11 11:21:51.360863: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n","\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n","2023-05-11 11:21:51.519174: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n","\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n","2023-05-11 11:21:51.571940: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n","\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n","2023-05-11 11:21:51.573695: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n","\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n","2023-05-11 11:21:51.575014: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n","\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n","2023-05-11 11:21:51.784270: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n","\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n","2023-05-11 11:21:51.785959: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n","\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n","2023-05-11 11:21:51.787324: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n","\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n","2023-05-11 11:21:51.942191: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n","\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n","2023-05-11 11:21:51.994131: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n","\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n","2023-05-11 11:21:51.995957: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n","\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n","2023-05-11 11:21:51.997319: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n","\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n","2023-05-11 11:21:52.497168: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n","\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n","2023-05-11 11:21:52.950312: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n","\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n","2023-05-11 11:21:53.773634: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n","\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n","2023-05-11 11:21:53.775023: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n","\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n","2023-05-11 11:21:53.776097: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n","\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n","2023-05-11 11:21:53.912593: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n","\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n","2023-05-11 11:21:53.958788: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n","\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n","2023-05-11 11:21:53.959925: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n","\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n","2023-05-11 11:21:53.960960: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n","\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n","2023-05-11 11:21:54.146963: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n","\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n","2023-05-11 11:21:54.148314: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n","\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n","2023-05-11 11:21:54.149386: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n","\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n","2023-05-11 11:21:54.287233: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n","\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n","2023-05-11 11:21:54.333644: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n","\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n","2023-05-11 11:21:54.334790: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n","\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n","2023-05-11 11:21:54.335865: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n","\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n","2023-05-11 11:21:54.832904: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n","\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n","2023-05-11 11:21:55.271601: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n","\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n","2023-05-11 11:21:56.929840: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:429] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED\n","2023-05-11 11:21:56.929922: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:438] Possibly insufficient driver version: 530.41.3\n","2023-05-11 11:21:56.929951: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at cudnn_rnn_ops.cc:1554 : UNKNOWN: Fail to find the dnn implementation.\n","2023-05-11 11:21:56.929979: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): UNKNOWN: Fail to find the dnn implementation.\n","\t [[{{node CudnnRNN}}]]\n","2023-05-11 11:21:56.930049: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): UNKNOWN: {{function_node __forward_gpu_lstm_with_fallback_8137_specialized_for_model_LSTM_bidirectional_backward_lstm_PartitionedCall_at___inference_train_function_11560}} {{function_node __forward_gpu_lstm_with_fallback_8137_specialized_for_model_LSTM_bidirectional_backward_lstm_PartitionedCall_at___inference_train_function_11560}} Fail to find the dnn implementation.\n","\t [[{{node CudnnRNN}}]]\n","\t [[model_LSTM/bidirectional/backward_lstm/PartitionedCall]]\n","2023-05-11 11:21:56.931033: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:429] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n","2023-05-11 11:21:56.931080: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at cudnn_rnn_ops.cc:1554 : UNKNOWN: Fail to find the dnn implementation.\n","2023-05-11 11:21:56.931107: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): UNKNOWN: Fail to find the dnn implementation.\n","\t [[{{node CudnnRNN}}]]\n"]},{"ename":"UnknownError","evalue":"Graph execution error:\n\nFail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[model_LSTM/bidirectional/backward_lstm/PartitionedCall]] [Op:__inference_train_function_11560]","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[27], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39m# fit the model\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m# with tf.device('/GPU:0'):\u001b[39;00m\n\u001b[1;32m     14\u001b[0m start \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow()\n\u001b[0;32m---> 15\u001b[0m history_model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_dataset,\n\u001b[1;32m     16\u001b[0m                         batch_size\u001b[39m=\u001b[39;49m\u001b[39m2048\u001b[39;49m,\n\u001b[1;32m     17\u001b[0m                         steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(train_dataset),\n\u001b[1;32m     18\u001b[0m                         validation_data\u001b[39m=\u001b[39;49mvalid_dataset,\n\u001b[1;32m     19\u001b[0m                         validation_steps\u001b[39m=\u001b[39;49m\u001b[39mint\u001b[39;49m(\u001b[39mlen\u001b[39;49m(valid_dataset)),\n\u001b[1;32m     20\u001b[0m                         callbacks\u001b[39m=\u001b[39;49m[early_stopping, reduce_lr],\n\u001b[1;32m     21\u001b[0m                         epochs\u001b[39m=\u001b[39;49mepoch) \n\u001b[1;32m     22\u001b[0m end \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow()\n\u001b[1;32m     23\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe time taken to train the model is \u001b[39m\u001b[39m{\u001b[39;00mend\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39mstart\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:552\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    542\u001b[0m try_log_autologging_event(\n\u001b[1;32m    543\u001b[0m     AutologgingEventLogger\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39mlog_patch_function_start,\n\u001b[1;32m    544\u001b[0m     session,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    548\u001b[0m     kwargs,\n\u001b[1;32m    549\u001b[0m )\n\u001b[1;32m    551\u001b[0m \u001b[39mif\u001b[39;00m patch_is_class:\n\u001b[0;32m--> 552\u001b[0m     patch_function\u001b[39m.\u001b[39;49mcall(call_original, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    553\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    554\u001b[0m     patch_function(call_original, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:170\u001b[0m, in \u001b[0;36mPatchFunction.call\u001b[0;34m(cls, original, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    169\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mcls\u001b[39m, original, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 170\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(original, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:181\u001b[0m, in \u001b[0;36mPatchFunction.__call__\u001b[0;34m(self, original, *args, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_on_exception(e)\n\u001b[1;32m    178\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[39m# Regardless of what happens during the `_on_exception` callback, reraise\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     \u001b[39m# the original implementation exception once the callback completes\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m     \u001b[39mraise\u001b[39;00m e\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:174\u001b[0m, in \u001b[0;36mPatchFunction.__call__\u001b[0;34m(self, original, *args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, original, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    173\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_patch_implementation(original, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    175\u001b[0m     \u001b[39mexcept\u001b[39;00m (\u001b[39mException\u001b[39;00m, \u001b[39mKeyboardInterrupt\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    176\u001b[0m         \u001b[39mtry\u001b[39;00m:\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:232\u001b[0m, in \u001b[0;36mwith_managed_run.<locals>.PatchWithManagedRun._patch_implementation\u001b[0;34m(self, original, *args, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m mlflow\u001b[39m.\u001b[39mactive_run():\n\u001b[1;32m    230\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanaged_run \u001b[39m=\u001b[39m create_managed_run()\n\u001b[0;32m--> 232\u001b[0m result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_patch_implementation(original, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    234\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanaged_run:\n\u001b[1;32m    235\u001b[0m     mlflow\u001b[39m.\u001b[39mend_run(RunStatus\u001b[39m.\u001b[39mto_string(RunStatus\u001b[39m.\u001b[39mFINISHED))\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/mlflow/tensorflow/__init__.py:1255\u001b[0m, in \u001b[0;36mautolog.<locals>.FitPatch._patch_implementation\u001b[0;34m(self, original, inst, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1252\u001b[0m early_stop_callback \u001b[39m=\u001b[39m _get_early_stop_callback(callbacks)\n\u001b[1;32m   1253\u001b[0m _log_early_stop_callback_params(early_stop_callback)\n\u001b[0;32m-> 1255\u001b[0m history \u001b[39m=\u001b[39m original(inst, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1257\u001b[0m \u001b[39mif\u001b[39;00m log_models:\n\u001b[1;32m   1258\u001b[0m     _log_keras_model(history, args)\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:535\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001b[0;34m(*og_args, **og_kwargs)\u001b[0m\n\u001b[1;32m    532\u001b[0m         original_result \u001b[39m=\u001b[39m original(\u001b[39m*\u001b[39m_og_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_og_kwargs)\n\u001b[1;32m    533\u001b[0m         \u001b[39mreturn\u001b[39;00m original_result\n\u001b[0;32m--> 535\u001b[0m \u001b[39mreturn\u001b[39;00m call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:470\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001b[0;34m(original_fn, og_args, og_kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     try_log_autologging_event(\n\u001b[1;32m    463\u001b[0m         AutologgingEventLogger\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39mlog_original_function_start,\n\u001b[1;32m    464\u001b[0m         session,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    468\u001b[0m         og_kwargs,\n\u001b[1;32m    469\u001b[0m     )\n\u001b[0;32m--> 470\u001b[0m     original_fn_result \u001b[39m=\u001b[39m original_fn(\u001b[39m*\u001b[39;49mog_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mog_kwargs)\n\u001b[1;32m    472\u001b[0m     try_log_autologging_event(\n\u001b[1;32m    473\u001b[0m         AutologgingEventLogger\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39mlog_original_function_success,\n\u001b[1;32m    474\u001b[0m         session,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    478\u001b[0m         og_kwargs,\n\u001b[1;32m    479\u001b[0m     )\n\u001b[1;32m    480\u001b[0m     \u001b[39mreturn\u001b[39;00m original_fn_result\n","File \u001b[0;32m~/.local/lib/python3.11/site-packages/mlflow/utils/autologging_utils/safety.py:532\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001b[0;34m(*_og_args, **_og_kwargs)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[39m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001b[39;00m\n\u001b[1;32m    525\u001b[0m \u001b[39m# during original function execution, even if silent mode is enabled\u001b[39;00m\n\u001b[1;32m    526\u001b[0m \u001b[39m# (`silent=True`), since these warnings originate from the ML framework\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \u001b[39m# or one of its dependencies and are likely relevant to the caller\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[39mwith\u001b[39;00m set_non_mlflow_warnings_behavior_for_current_thread(\n\u001b[1;32m    529\u001b[0m     disable_warnings\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    530\u001b[0m     reroute_warnings\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    531\u001b[0m ):\n\u001b[0;32m--> 532\u001b[0m     original_result \u001b[39m=\u001b[39m original(\u001b[39m*\u001b[39;49m_og_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_og_kwargs)\n\u001b[1;32m    533\u001b[0m     \u001b[39mreturn\u001b[39;00m original_result\n","File \u001b[0;32m/usr/lib/python3.11/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/usr/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nFail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[model_LSTM/bidirectional/backward_lstm/PartitionedCall]] [Op:__inference_train_function_11560]"]}],"source":["# fit the model\n","import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","tf.get_logger().setLevel('ERROR')\n","tf.autograph.set_verbosity(1)\n","tf.set_seed = 42\n","\n","start = datetime.now()\n","with mlflow.start_run():\n","    mlflow.tensorflow.autolog()\n","    \n","    # fit the model\n","    # with tf.device('/GPU:0'):\n","    start = datetime.now()\n","    history_model = model.fit(train_dataset,\n","                            batch_size=2048,\n","                            steps_per_epoch=len(train_dataset),\n","                            validation_data=valid_dataset,\n","                            validation_steps=int(len(valid_dataset)),\n","                            callbacks=[early_stopping, reduce_lr],\n","                            epochs=epoch) \n","    end = datetime.now()\n","    print(f\"The time taken to train the model is {end - start}\")\n","        \n","    # Evaluate model\n","    model.evaluate(test_dataset)\n","    \n","    mlflow.log_param(\"Model\"   , \"LSTM\")\n","    mlflow.log_param(\"Dataset\" , f'{load_data_path}')\n","    # mlflow.log_params(model_results)\n","    mlflow.tensorflow.autolog()\n","    \n","    # Calculate the metrics\n","    model_preds_probs   = model.predict(test_feature)\n","    av_precision    = average_precision_score(test_label, model_preds_probs)\n","    print(av_precision)\n","    mlflow.log_metric(\"av_precision\"   , av_precision)\n","\n","print(\"________________________________________\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# # Calculate the metrics\n","# model_preds_probs   = model.predict(test_feature)\n","# av_precision    = average_precision_score(test_label, model_preds_probs)\n","# av_precision"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Build the model \n","input_shape = 4\n","\n","inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n","x = layers.Dense(32, activation ='relu')(inputs)\n","x = layers.Dense(64, activation = 'relu')(x)\n","x = layers.BatchNormalization()(x)\n","x = layers.Dropout(0.1)(x)\n","x = layers.Dense(128, activation ='relu')(x)\n","x = layers.Dense(512, activation = 'relu')(x)\n","x = layers.BatchNormalization()(x)\n","x = layers.Dropout(0.25)(x)\n","x = layers.Dense(1024, activation ='relu')(x)\n","x = layers.Dense(512, activation = 'relu')(x)\n","x = layers.BatchNormalization()(x)\n","x = layers.Dropout(0.5)(x)\n","x = layers.Dense(128, activation=\"relu\")(x)\n","x = layers.Dense(64, activation=\"relu\")(x)\n","x = layers.Dense(32, activation=\"relu\")(x)\n","outputs = layers.Dense(4, activation=\"softmax\",name=\"output_layer\")(x)      \n","model_DNN = tf.keras.Model(inputs, outputs) \n","\n","model_DNN.compile(loss=\"categorical_crossentropy\",\n","              optimizer=tf.keras.optimizers.Adam(),\n","              metrics=[\"accuracy\"])\n","\n","model_DNN.summary()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Fit the model\n","import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","tf.get_logger().setLevel('ERROR')\n","tf.autograph.set_verbosity(1)\n","tf.set_seed = 42\n","np.random.seed(40)\n","counter = 1\n","epoch = 5\n","Model_Name = 'DNN_model'\n","\n","\n","with mlflow.start_run():\n","    mlflow.tensorflow.autolog()\n","    \n","    # fit the model\n","    # with tf.device('/GPU:0'):\n","    start = datetime.now()\n","    history_model = model_DNN.fit(train_dataset,\n","                                  batch_size=2048,\n","                                  steps_per_epoch=len(train_dataset),\n","                                  validation_data=valid_dataset,\n","                                  validation_steps=int(len(valid_dataset)),\n","                                  callbacks=[early_stopping, reduce_lr],\n","                                  epochs=epoch) \n","    end = datetime.now()\n","    print(f\"The time taken to train the model is {end - start}\")\n","        \n","    # Evaluate model\n","    model_DNN.evaluate(test_dataset)\n","    \n","    # Calculate the metrics\n","    # model_results = eval_metrics(model, \n","    #                              test_features = test_feature,\n","    #                              test_labels = test_label)\n","    \n","    mlflow.log_param(\"Model\"           , Model_Name)\n","    mlflow.log_param(\"Dataset\" , f'{load_data_path}')\n","    # mlflow.log_params(model_results)\n","    mlflow.tensorflow.autolog()\n","    \n","    # Calculate the metrics\n","    model_preds_probs   = model_DNN.predict(test_feature)\n","    av_precision    = average_precision_score(test_label, model_preds_probs)\n","    print(av_precision)\n","    mlflow.log_metric(\"av_precision\"   , av_precision)\n","    \n","    \n","    print(\"________________________________________\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# model_preds_probs   = model_DNN.predict(test_feature)\n","# av_precision    = average_precision_score(test_label, model_preds_probs)\n","# print(av_precision)\n","# mlflow.log_metric(\"av_precision\"   , av_precision)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Final test"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# import os \n","# import pandas as pd\n","\n","# def import_test_file_from_folder(file_path):\n","#     test_file = pd.read_csv(file_path)\n","#     name = os.path.basename(file_path)\n","#     id_value = name.split('.')[0]\n","#     test_file['Id_value'] = id_value\n","#     test_file['Id'] = test_file['Id_value'].astype(str) + '_' + test_file['Time'].astype(str)\n","#     test_file = test_file[['Id','AccV','AccML','AccAP']]\n","#     return test_file\n","\n","# def preprocessing_test_dataset(df):\n","#     import random \n","#     random_seed = 54\n","    \n","#     feature_col = ['AccV','AccML','AccAP']\n","#     feature_dataset = df[feature_col]\n","\n","#     feature_dataset=np.array(feature_dataset)\n","#     return feature_dataset\n","\n","# def make_prediction(Models, test_submit):\n","#     for Model_Name, classifier in Models.items(): \n","#         test_submit_pred = classifier.predict(test_submit)\n","#     print(f\"The prediciton is {test_submit_pred.shape}\")\n","#     return test_submit_pred\n","\n","# def test_submission_file(test_file, predicit_score_np):\n","#     test_score_df = pd.DataFrame(predicit_score_np, columns=['StartHesitation', 'Turn', 'Walking', 'All_zero'])\n","#     df = pd.concat([test_file, test_score_df], ignore_index= False, sort=False, axis=1)\n","#     select_column = ['Id','StartHesitation', 'Turn', 'Walking']\n","#     submit_dataset = df[select_column]\n","#     return submit_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# test_file_path = ('/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/test')\n","# test_defog_path = testfile_path+'defog/02ab235146.csv'\n","# test_tdcsfog_path = test_file_path+'tdcsfog/003f117e14.csv'"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# test_defog = import_test_file_from_folder(test_defog_path)\n","# test_tdcsfog = import_test_file_from_folder(test_tdcsfog_path)\n","\n","# test_df =  pd.concat([test_tdcsfog, test_defog])\n","# print(test_df.head(), test_df.shape)\n","# test_submit = preprocessing_test_dataset(test_df)\n","# print(test_submit.head())\n","# test_submit_pred = make_prediction(Models, test_submit)\n","# test_submission_file = test_submission_file(test_df, test_submit_pred)\n","# print(test_submission_file.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# test_submission_file.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# submission_sample = pd.read_csv('/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/sample_submission.csv')\n","# submission_sample.shape == test_submission_file.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# test_submission_file.to_csv('submission.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":4}
