{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ### bz of low on ram reinput the dataset\n",
    "import pandas as pd\n",
    "# clean_defog_dataset = pd.read_parquet('Data/clean/clean_defog_dataset.parquet')\n",
    "# clean_tdcsfog_dataset = pd.read_parquet('Data/clean/clean_tdcsfog_dataset.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_dataset = pd.concat([clean_tdcsfog_dataset,clean_defog_dataset])\n",
    "# clean_dataset.shape[0] == clean_defog_dataset.shape[0]+clean_tdcsfog_dataset.shape[0]\n",
    "# clean_dataset.to_parquet('Data/clean/clean_mix_dataset.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "clean_dataset = pd.read_parquet('Data/clean/clean_mix_dataset.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       AccV     AccML     AccAP  StartHesitation  Turn  Walking  All_zero\n",
       " 0 -9.563005  0.147211  1.043645                0     0        0       1.0\n",
       " 1 -9.560686  0.156369  1.032437                0     0        0       1.0\n",
       " 2 -9.554016  0.149317  1.039120                0     0        0       1.0\n",
       " 3 -9.558530  0.149386  1.043640                0     0        0       1.0\n",
       " 4 -9.558615  0.142463  1.032258                0     0        0       1.0,\n",
       " (19089710, 7))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_dataset.head(),clean_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversampling(clean_dataset):\n",
    "    feature_col = ['AccV','AccML','AccAP']\n",
    "    label_col = ['StartHesitation','Turn','Walking', 'All_zero']\n",
    "\n",
    "    feature_dataset = clean_dataset[feature_col]\n",
    "    label_dataset = clean_dataset[label_col]\n",
    "    print(f\"The Feature :{feature_dataset.shape}, \\n\"\n",
    "          f\"The label {label_dataset.shape}\")\n",
    "    \n",
    "    print(f\"Because of Four Classes are imbalanced. To get high accuracy, oversampling is used\")\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    import numpy as np\n",
    "    # Instantiate the MultiLabelUnderSampler\n",
    "    over_sampler = SMOTE()\n",
    "\n",
    "    # Undersample the dataset\n",
    "    X_resampled, y_resampled = over_sampler.fit_resample(feature_dataset.to_numpy(), label_dataset.to_numpy())\n",
    "    \n",
    "    SMOTE_features_dataset = pd.DataFrame(X_resampled, columns=feature_dataset.columns)\n",
    "    \n",
    "    \n",
    "    SMOTE_labels_dataset = pd.DataFrame(y_resampled, columns=label_dataset.columns)\n",
    "    print(f\"The over sampling label shape : {SMOTE_labels_dataset.shape}\")\n",
    "    \n",
    "    def check_all_four_class_condition(df):\n",
    "        print(f\"Check all four check condiiton in {df}\")\n",
    "        a = df[df.StartHesitation == 1].shape[0]\n",
    "        b = df[df.Turn == 1].shape[0]\n",
    "        c = df[df.Walking ==1].shape[0]\n",
    "        d = df[df.All_zero == 1].shape[0]\n",
    "        print(f\"Number of Start Hesitation : {a}, \\n\"\n",
    "              f\"Number of Turn : {b}, \\n\"  \n",
    "              f\"Number of Walking : {c}, \\n\"\n",
    "              f\"Number of All_zero : {d}\")\n",
    "        print(\"Is Number of All four class is equal to total sampling :\",\n",
    "             df.shape[0] == a + b + c + d)\n",
    "        \n",
    "    check_all_four_class_condition(SMOTE_labels_dataset)\n",
    "    \n",
    "    oversampling_dataset = pd.concat([SMOTE_features_dataset,SMOTE_labels_dataset], \n",
    "                                     ignore_index= False, sort=False, axis=1)\n",
    "    print(f\"The shape of oversampling dataset is : {oversampling_dataset.shape[0]}\")\n",
    "    print(f\"The number of duplication in dataset : {oversampling_dataset.duplicated().sum()}\")\n",
    "    # Drop duplication\n",
    "    oversampling_dataset.drop_duplicates(inplace=True)\n",
    "    print(f\"The shape of oversampling after remove duplication :{oversampling_dataset.shape}\")\n",
    "  \n",
    "    return oversampling_dataset\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Feature :(19089710, 3), \n",
      "The label (19089710, 4)\n",
      "Because of Four Classes are imbalanced. To get high accuracy, oversampling is used\n",
      "The over sampling label shape : (64970492, 4)\n",
      "Check all four check condiiton in           StartHesitation  Turn  Walking  All_zero\n",
      "0                       0     0        0         1\n",
      "1                       0     0        0         1\n",
      "2                       0     0        0         1\n",
      "3                       0     0        0         1\n",
      "4                       0     0        0         1\n",
      "...                   ...   ...      ...       ...\n",
      "64970487                0     0        1         0\n",
      "64970488                0     0        1         0\n",
      "64970489                0     0        1         0\n",
      "64970490                0     0        1         0\n",
      "64970491                0     0        1         0\n",
      "\n",
      "[64970492 rows x 4 columns]\n",
      "Number of Start Hesitation : 16242623, \n",
      "Number of Turn : 16242623, \n",
      "Number of Walking : 16242623, \n",
      "Number of All_zero : 16242623\n",
      "Is Number of All four class is equal to total sampling : True\n",
      "The shape of oversampling dataset is : 64970492\n",
      "The number of duplication in dataset : 1\n",
      "The shape of oversampling after remove duplication :(64970491, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AccV</th>\n",
       "      <th>AccML</th>\n",
       "      <th>AccAP</th>\n",
       "      <th>StartHesitation</th>\n",
       "      <th>Turn</th>\n",
       "      <th>Walking</th>\n",
       "      <th>All_zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.563005</td>\n",
       "      <td>0.147211</td>\n",
       "      <td>1.043645</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.560686</td>\n",
       "      <td>0.156369</td>\n",
       "      <td>1.032437</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9.554016</td>\n",
       "      <td>0.149317</td>\n",
       "      <td>1.039120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9.558530</td>\n",
       "      <td>0.149386</td>\n",
       "      <td>1.043640</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9.558615</td>\n",
       "      <td>0.142463</td>\n",
       "      <td>1.032258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AccV     AccML     AccAP  StartHesitation  Turn  Walking  All_zero\n",
       "0 -9.563005  0.147211  1.043645                0     0        0         1\n",
       "1 -9.560686  0.156369  1.032437                0     0        0         1\n",
       "2 -9.554016  0.149317  1.039120                0     0        0         1\n",
       "3 -9.558530  0.149386  1.043640                0     0        0         1\n",
       "4 -9.558615  0.142463  1.032258                0     0        0         1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oversampling_dataset = oversampling(clean_dataset)\n",
    "oversampling_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampling_dataset.to_parquet('Data/clean/oversampling_mix_dataset.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(oversampling_dataset):\n",
    "        \n",
    "    # 60% Train Data, 20% Validation Data, 20% Test Data\n",
    "    # 80% Set Data(60% rain Data, 20% Validation Data) , 20% Test Data\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import random \n",
    "    random_seed = 54\n",
    "    set_data, test_data = train_test_split(oversampling_dataset, test_size=0.2, random_state=True)\n",
    "    print(f\"The set data shape : {set_data.shape}\\n\"\n",
    "          f\"The test data shape : {test_data.shape}\\n\"\n",
    "          f\"Is the dataset still in range : \"\n",
    "          f\"{oversampling_dataset.shape[0] == set_data.shape[0] + test_data.shape[0]}\")\n",
    "    \n",
    "    print(f\"Again Search for duplicaiton : \\n \"\n",
    "          f\"Set Data :{set_data.duplicated().sum()} \\n\"\n",
    "          f\"Test Data :{test_data.duplicated().sum()}\")\n",
    "    \n",
    "    print(\"All task are finish\")\n",
    "    return set_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The set data shape : (15271768, 7)\n",
      "The test data shape : (3817942, 7)\n",
      "Is the dataset still in range : True\n",
      "Again Search for duplicaiton : \n",
      " Set Data :0 \n",
      "Test Data :0\n",
      "All task are finish\n"
     ]
    }
   ],
   "source": [
    "set_data , test_data = split(clean_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_data.to_parquet('Data/Process/set_mix_data.parquet')\n",
    "# test_data.to_parquet('Data/Process/test_mix_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_the_dataset(df):\n",
    "\n",
    "    import random \n",
    "    random_seed = 54\n",
    "    \n",
    "    feature_col = ['AccV','AccML','AccAP']\n",
    "    label_col = ['StartHesitation','Turn','Walking', 'All_zero']\n",
    "\n",
    "    # make feature and label\n",
    "    feature_dataset = df[feature_col]\n",
    "    label_dataset = df[label_col]\n",
    "    \n",
    "    \n",
    "    print(\"Train test split begin\")\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_feature, valid_feature, train_label, valid_label = train_test_split(feature_dataset, label_dataset, test_size=0.2, random_state=True)\n",
    "    \n",
    "    train_feature = np.array(train_feature) \n",
    "    valid_feature = np.array(valid_feature)\n",
    "    train_label  = np.array(train_label)\n",
    "    valid_label = np.array(valid_label)\n",
    "    print(\"All task are finish\")\n",
    "    \n",
    "    return train_feature, valid_feature, train_label, valid_label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train test split begin\n",
      "All task are finish\n"
     ]
    }
   ],
   "source": [
    "train_feature, valid_feature, train_label, valid_label = preprocessing_the_dataset(set_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_test_dataset(df):\n",
    "\n",
    "    import random \n",
    "    random_seed = 54\n",
    "    \n",
    "    feature_col = ['AccV','AccML','AccAP']\n",
    "    label_col = ['StartHesitation','Turn','Walking', 'All_zero']\n",
    "\n",
    "    # make feature and label\n",
    "    feature_dataset = df[feature_col]\n",
    "    label_dataset = df[label_col]\n",
    "    \n",
    "    feature_dataset = np.array(feature_dataset) \n",
    "    label_dataset  = np.array(label_dataset)\n",
    "    print(\"All task are finish\")\n",
    "    \n",
    "    return feature_dataset, label_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All task are finish\n"
     ]
    }
   ],
   "source": [
    "test_feature, test_label = preprocessing_test_dataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12217414, 3),\n",
       " (12217414, 4),\n",
       " (3054354, 3),\n",
       " (12217414, 4),\n",
       " (3054354, 4),\n",
       " (3817942, 3),\n",
       " (3817942, 4))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature.shape, train_label.shape, valid_feature.shape, train_label.shape, valid_label.shape, test_feature.shape, test_label.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Data/mix/train_feature.npy',train_feature) \n",
    "np.save('Data/mix/valid_feature.npy', valid_feature)\n",
    "np.save('Data/mix/train_label.npy', train_label)\n",
    "np.save('Data/mix/valid_label.npy',valid_label)\n",
    "np.save('Data/mix/test_feature.npy',test_feature)\n",
    "np.save('Data/mix/test_label.npy',test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_feature = np.load('Data/mix/train_feature.npy')\n",
    "# valid_feature = np.load('Data/mix/valid_feature.npy')\n",
    "# test_feature = np.load('Data/mix/test_feature.npy')\n",
    "# train_label = np.load('Data/mix/train_label.npy')\n",
    "# valid_label = np.load('Data/mix/valid_label.npy')\n",
    "# test_label = np.load('Data/mix/test_label.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
