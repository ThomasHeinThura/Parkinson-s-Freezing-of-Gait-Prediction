{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ### bz of low on ram reinput the dataset\n",
    "import pandas as pd\n",
    "# clean_defog_dataset = pd.read_parquet('Data/clean/clean_defog_dataset.parquet')\n",
    "# clean_tdcsfog_dataset = pd.read_parquet('Data/clean/clean_tdcsfog_dataset.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_dataset = pd.concat([clean_tdcsfog_dataset,clean_defog_dataset])\n",
    "# clean_dataset.shape[0] == clean_defog_dataset.shape[0]+clean_tdcsfog_dataset.shape[0]\n",
    "# clean_dataset.to_parquet('Data/clean/clean_mix_dataset.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dataset = pd.read_parquet('Data/clean/clean_mix_dataset.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversampling(clean_dataset):\n",
    "    feature_col = ['AccV','AccML','AccAP']\n",
    "    label_col = ['StartHesitation','Turn','Walking', 'All_zero']\n",
    "\n",
    "    feature_dataset = clean_dataset[feature_col]\n",
    "    label_dataset = clean_dataset[label_col]\n",
    "    print(f\"The Feature :{feature_dataset.shape}, \\n\"\n",
    "          f\"The label {label_dataset.shape}\")\n",
    "    \n",
    "    print(f\"Because of Four Classes are imbalanced. To get high accuracy, oversampling is used\")\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    import numpy as np\n",
    "    # Instantiate the MultiLabelUnderSampler\n",
    "    over_sampler = SMOTE()\n",
    "\n",
    "    # Undersample the dataset\n",
    "    X_resampled, y_resampled = over_sampler.fit_resample(feature_dataset.to_numpy(), label_dataset.to_numpy())\n",
    "    \n",
    "    SMOTE_features_dataset = pd.DataFrame(X_resampled, columns=feature_dataset.columns)\n",
    "    \n",
    "    \n",
    "    SMOTE_labels_dataset = pd.DataFrame(y_resampled, columns=label_dataset.columns)\n",
    "    print(f\"The over sampling label shape : {SMOTE_labels_dataset.shape}\")\n",
    "    \n",
    "    def check_all_four_class_condition(df):\n",
    "        print(f\"Check all four check condiiton in {df}\")\n",
    "        a = df[df.StartHesitation == 1].shape[0]\n",
    "        b = df[df.Turn == 1].shape[0]\n",
    "        c = df[df.Walking ==1].shape[0]\n",
    "        d = df[df.All_zero == 1].shape[0]\n",
    "        print(f\"Number of Start Hesitation : {a}, \\n\"\n",
    "              f\"Number of Turn : {b}, \\n\"  \n",
    "              f\"Number of Walking : {c}, \\n\"\n",
    "              f\"Number of All_zero : {d}\")\n",
    "        print(\"Is Number of All four class is equal to total sampling :\",\n",
    "             df.shape[0] == a + b + c + d)\n",
    "        \n",
    "    check_all_four_class_condition(SMOTE_labels_dataset)\n",
    "    \n",
    "    oversampling_dataset = pd.concat([SMOTE_features_dataset,SMOTE_labels_dataset], \n",
    "                                     ignore_index= False, sort=False, axis=1)\n",
    "    print(f\"The shape of oversampling dataset is : {oversampling_dataset.shape[0]}\")\n",
    "    print(f\"The number of duplication in dataset : {oversampling_dataset.duplicated().sum()}\")\n",
    "    # Drop duplication\n",
    "    oversampling_dataset.drop_duplicates(inplace=True)\n",
    "    print(f\"The shape of oversampling after remove duplication :{oversampling_dataset.shape}\")\n",
    "  \n",
    "    return oversampling_dataset\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Feature :(19089710, 3), \n",
      "The label (19089710, 4)\n",
      "Because of Four Classes are imbalanced. To get high accuracy, oversampling is used\n",
      "The over sampling label shape : (64970492, 4)\n",
      "Check all four check condiiton in           StartHesitation  Turn  Walking  All_zero\n",
      "0                       0     0        0         1\n",
      "1                       0     0        0         1\n",
      "2                       0     0        0         1\n",
      "3                       0     0        0         1\n",
      "4                       0     0        0         1\n",
      "...                   ...   ...      ...       ...\n",
      "64970487                0     0        1         0\n",
      "64970488                0     0        1         0\n",
      "64970489                0     0        1         0\n",
      "64970490                0     0        1         0\n",
      "64970491                0     0        1         0\n",
      "\n",
      "[64970492 rows x 4 columns]\n",
      "Number of Start Hesitation : 16242623, \n",
      "Number of Turn : 16242623, \n",
      "Number of Walking : 16242623, \n",
      "Number of All_zero : 16242623\n",
      "Is Number of All four class is equal to total sampling : True\n",
      "The shape of oversampling dataset is : 64970492\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "oversampling_dataset = oversampling(clean_dataset)\n",
    "oversampling.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampling_dataset.to_parquet('Data/clean/oversampling_mix_dataset.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(oversampling_dataset):\n",
    "        \n",
    "    # 60% Train Data, 20% Validation Data, 20% Test Data\n",
    "    # 80% Set Data(60% rain Data, 20% Validation Data) , 20% Test Data\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import random \n",
    "    random_seed = 54\n",
    "    set_data, test_data = train_test_split(oversampling_dataset, test_size=0.2, random_state=True)\n",
    "    print(f\"The set data shape : {set_data.shape}\\n\"\n",
    "          f\"The test data shape : {test_data.shape}\\n\"\n",
    "          f\"Is the dataset still in range : \"\n",
    "          f\"{oversampling_dataset.shape[0] == set_data.shape[0] + test_data.shape[0]}\")\n",
    "    \n",
    "    print(f\"Again Search for duplicaiton : \\n \"\n",
    "          f\"Set Data :{set_data.duplicated().sum()} \\n\"\n",
    "          f\"Test Data :{test_data.duplicated().sum()}\")\n",
    "    \n",
    "    check_all_four_class_condition(set_data)\n",
    "    check_all_four_class_condition(test_data)\n",
    "    print(\"All task are finish\")\n",
    "    return set_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_data , test_data = oversampling_and_split(clean_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_data.to_parquet('Data/Process/set_mix_data.parquet')\n",
    "test_data.to_parquet('Data/Process/test_mix_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_the_dataset(df):\n",
    "\n",
    "    import random \n",
    "    random_seed = 54\n",
    "    \n",
    "    feature_col = ['AccV','AccML','AccAP']\n",
    "    label_col = ['StartHesitation','Turn','Walking', 'All_zero']\n",
    "\n",
    "    # make feature and label\n",
    "    feature_dataset = df[feature_col]\n",
    "    label_dataset = df[label_col]\n",
    "    \n",
    "    \n",
    "    print(\"Train test split begin\")\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_feature, valid_feature, train_label, valid_label = train_test_split(feature_dataset, label_dataset, test_size=0.2, random_state=True)\n",
    "    \n",
    "    train_feature = np.array(train_feature) \n",
    "    valid_feature = np.array(valid_feature)\n",
    "    train_label  = np.array(train_label)\n",
    "    valid_label = np.array(valid_label)\n",
    "    print(\"All task are finish\")\n",
    "    \n",
    "    return train_feature, valid_feature, train_label, valid_label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_test_dataset(df):\n",
    "\n",
    "    import random \n",
    "    random_seed = 54\n",
    "    \n",
    "    feature_col = ['AccV','AccML','AccAP']\n",
    "    label_col = ['StartHesitation','Turn','Walking', 'All_zero']\n",
    "\n",
    "    # make feature and label\n",
    "    feature_dataset = df[feature_col]\n",
    "    label_dataset = df[label_col]\n",
    "    \n",
    "    feature_dataset = np.array(feature_dataset) \n",
    "    label_dataset  = np.array(label_dataset)\n",
    "    print(\"All task are finish\")\n",
    "    \n",
    "    return feature_dataset, label_dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
