{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 09:11:51.019444: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from datetime import datetime\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(1)\n",
    "tf.set_seed = 42\n",
    "\n",
    "\n",
    "train_feature = np.load('Data/tdcsfog/train_feature.npy')\n",
    "valid_feature = np.load('Data/tdcsfog/valid_feature.npy')\n",
    "test_feature = np.load('Data/tdcsfog/test_feature.npy')\n",
    "train_label = np.load('Data/tdcsfog/train_label.npy')\n",
    "valid_label = np.load('Data/tdcsfog/valid_label.npy')\n",
    "test_label = np.load('Data/tdcsfog/test_label.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12454643, 3),\n",
       " (3113661, 3),\n",
       " (12454643, 4),\n",
       " (3113661, 4),\n",
       " (3892076, 3),\n",
       " (3892076, 4))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature.shape, valid_feature.shape, train_label.shape, valid_label.shape, test_feature.shape, test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.44120461, -0.082227  , -1.21183151],\n",
       "        [-0.44090003, -1.08226973,  0.45736664],\n",
       "        [-0.60049354, -0.53963709, -1.42609465],\n",
       "        ...,\n",
       "        [ 0.44363822,  1.50481888,  2.06660539],\n",
       "        [ 0.53577687, -0.8985712 ,  1.23031254],\n",
       "        [ 0.5300372 , -1.09046895,  0.04516791]]),\n",
       " array([[ 1.21631488,  0.8841906 ,  0.54111506],\n",
       "        [ 0.02318879, -0.05761225,  1.06627182],\n",
       "        [-0.34960191,  0.3380232 ,  0.65026524],\n",
       "        ...,\n",
       "        [ 0.0700669 ,  0.3553626 , -0.5310615 ],\n",
       "        [-0.0840419 ,  0.89741266, -2.15641887],\n",
       "        [ 1.02971993, -0.21155021,  1.35195849]]),\n",
       " array([[-0.1616217 ,  0.58656796, -0.09556338],\n",
       "        [-1.1087879 , -0.57619191, -0.81476793],\n",
       "        [ 0.56795388, -0.3863001 ,  0.74809813],\n",
       "        ...,\n",
       "        [-0.16639802,  0.27430714, -0.51293622],\n",
       "        [-1.09601198, -2.18623926,  1.12397463],\n",
       "        [-0.43500182,  0.17089489, -0.41409062]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature, valid_feature, test_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 09:11:52.871375: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-09 09:11:52.890538: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-09 09:11:52.890739: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-09 09:11:52.893549: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-09 09:11:52.893747: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-09 09:11:52.893877: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-09 09:11:53.465817: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-09 09:11:53.465996: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-09 09:11:53.466134: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-09 09:11:53.466246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9781 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:0a:00.0, compute capability: 8.6\n",
      "2023-05-09 09:11:53.466702: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# Building the model and pipeline for Tensorflow \n",
    "# Preprocess the data\n",
    "# Turn our data into TensorFlow Datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_feature, train_label))\n",
    "train_dataset =  train_dataset.batch(2048).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((valid_feature,valid_label))\n",
    "valid_dataset = valid_dataset.batch(2048).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_feature,test_label))\n",
    "test_dataset = test_dataset.batch(2048).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'Data/defog/'\n",
    "# train_dataset.save(path+'train_dataset')\n",
    "# valid_dataset.save(path+'valid_dataset')\n",
    "# test_dataset.save(path+'test_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'Data/defog/'\n",
    "# train_dataset = tf.data.Dataset.load(path+'train_dataset')\n",
    "# valid_dataset = tf.data.Dataset.load(path+'valid_dataset')\n",
    "# test_dataset =  tf.data.Dataset.load(path+'test_dataset')\n",
    "# test_feature = np.load('Data/defog/test_feature.npy')\n",
    "# test_label = np.load('Data/defog/test_label.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 3), dtype=tf.float64, name=None), TensorSpec(shape=(None, 4), dtype=tf.int64, name=None))> \n",
      "Valid : <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 3), dtype=tf.float64, name=None), TensorSpec(shape=(None, 4), dtype=tf.int64, name=None))> \n",
      "Test : <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 3), dtype=tf.float64, name=None), TensorSpec(shape=(None, 4), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# Check the data shape\n",
    "# print(\n",
    "#     f\"Train_feature : {train_feature.shape} {train_feature.dtype} \\n\" \n",
    "#     f\"Train_labels : {train_label.shape} {train_label.dtype} \\n\" \n",
    "#     f\"Valid_feature : {valid_feature.shape} {valid_feature.dtype} \\n\" \n",
    "#     f\"Valid_label : {valid_label.shape} {valid_label.dtype} \"\n",
    "#     ) \n",
    "\n",
    "print(f\"Train : {train_dataset} \\n\"\n",
    "      f\"Valid : {valid_dataset} \\n\" \n",
    "      f\"Test : {test_dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", # watch the val loss metric\n",
    "                                                  patience=5) # if val loss decreases for 3 epochs in a row, stop training\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",  \n",
    "                                                 factor=0.2, # multiply the learning rate by 0.2 (reduce by 5x)\n",
    "                                                 patience=3,\n",
    "                                                 verbose=1, # print out when learning rate goes down \n",
    "                                                 min_lr=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 3)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                128       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,452\n",
      "Trainable params: 4,452\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model \n",
    "epoch = 10\n",
    "input_shape = 3\n",
    "\n",
    "inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
    "x = layers.Dense(32, activation ='relu')(inputs)\n",
    "x = layers.Dense(64, activation = 'relu')(x)\n",
    "# x = layers.BatchNormalization()(x)\n",
    "# x = layers.Dropout(0.1)(x)\n",
    "# x = layers.Dense(128, activation ='relu')(x)\n",
    "# x = layers.Dense(512, activation = 'relu')(x)\n",
    "# x = layers.BatchNormalization()(x)\n",
    "# x = layers.Dropout(0.25)(x)\n",
    "# x = layers.Dense(1024, activation ='relu')(x)\n",
    "# x = layers.Dense(512, activation = 'relu')(x)\n",
    "# x = layers.BatchNormalization()(x)\n",
    "# x = layers.Dropout(0.5)(x)\n",
    "# x = layers.Dense(128, activation=\"relu\")(x)\n",
    "# x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(4, activation=\"softmax\",name=\"output_layer\")(x)      \n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(40)\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.entities import ViewType\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "# !mlflow server --backend-store-uri sqlite:///backend.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(classifier, test_features, test_labels):\n",
    "    \n",
    "    from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "    \n",
    "    # make prediction\n",
    "    model_preds_probs   = classifier.predict(test_features)\n",
    "    model_preds         = tf.argmax(model_preds_probs, axis=1)\n",
    "    predictions         = tf.argmax(test_labels,axis=1)\n",
    "\n",
    "    \n",
    "    # Calculate model accuracy\n",
    "    # model_accuracy = accuracy_score(test_labels, predictions) * 100\n",
    "    # Calculate model precision, recall and f1 score using \"weighted average\n",
    "    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(test_labels, \n",
    "                                                                                 predictions, \n",
    "                                                                                 average=\"weighted\", \n",
    "                                                                                 zero_division= 1)\n",
    "    \n",
    "    av_precision    = average_precision_score(test_labels, predictions, zero_division= 1)\n",
    "    \n",
    "    model_results = {\n",
    "        # \"accuracy\": model_accuracy,\n",
    "        \"precision\": model_precision,\n",
    "        \"recall\": model_recall,\n",
    "        \"f1\": model_f1,\n",
    "        \"av precisoin\" : av_precision}\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # target_names = ['StartHesitation','Turn','Walking', 'All_zero']\n",
    "    # print(\"Classification report\")\n",
    "    # print(\"---------------------\",\"\\n\")\n",
    "    # print(classification_report(test_labels, predictions,target_names=target_names),\"\\n\")\n",
    "    # print(\"Confusion Matrix\")\n",
    "    # print(\"---------------------\",\"\\n\")\n",
    "    # print(f\"{Matrix} \\n\")\n",
    "\n",
    "    print(\"Accuracy Measures\")\n",
    "    print(\"---------------------\",\"\\n\")\n",
    "    # print(\"Accuracy: \", model_accuracy)\n",
    "    print(\"Avarge Precision: \", av_precision)\n",
    "    print(\"precision: \", model_precision)\n",
    "    print(\"recall : \", model_recall)\n",
    "    print(\"f1 : \", model_f1)\n",
    "    \n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking URI: 'http://127.0.0.1:5000'\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# how to check tensorflow version\n",
    "tf.__version__\n",
    "len(tf.config.list_physical_devices('GPU:0'))>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 09:12:05.437232: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [12454643,4]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-05-09 09:12:07.020635: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-05-09 09:12:07.022617: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x5636a064a980 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-05-09 09:12:07.022643: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2023-05-09 09:12:07.027744: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-05-09 09:12:07.434933: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8800\n",
      "2023-05-09 09:12:07.491853: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-05-09 09:12:07.546831: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6081/6082 [============================>.] - ETA: 0s - loss: 1.1565 - accuracy: 0.4689"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 09:12:25.426354: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [3113661,4]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6082/6082 [==============================] - 24s 4ms/step - loss: 1.1565 - accuracy: 0.4689 - val_loss: 1.1424 - val_accuracy: 0.4778 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "6082/6082 [==============================] - 21s 3ms/step - loss: 1.1411 - accuracy: 0.4778 - val_loss: 1.1381 - val_accuracy: 0.4798 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "6082/6082 [==============================] - 21s 3ms/step - loss: 1.1383 - accuracy: 0.4795 - val_loss: 1.1366 - val_accuracy: 0.4804 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "6082/6082 [==============================] - 21s 3ms/step - loss: 1.1367 - accuracy: 0.4802 - val_loss: 1.1355 - val_accuracy: 0.4808 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "6082/6082 [==============================] - 21s 3ms/step - loss: 1.1357 - accuracy: 0.4807 - val_loss: 1.1348 - val_accuracy: 0.4811 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "6082/6082 [==============================] - 21s 3ms/step - loss: 1.1349 - accuracy: 0.4811 - val_loss: 1.1342 - val_accuracy: 0.4814 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "5844/6082 [===========================>..] - ETA: 0s - loss: 1.1343 - accuracy: 0.4815"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "counter = 1\n",
    "Model_Name = 'DNN_model'\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(1)\n",
    "tf.set_seed = 42\n",
    "np.random.seed(40)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.tensorflow.autolog()\n",
    "    \n",
    "    # fit the model\n",
    "    # with tf.device('/GPU:0'):\n",
    "    start = datetime.now()\n",
    "    history_model = model.fit(train_dataset,\n",
    "                            batch_size=2048,\n",
    "                            steps_per_epoch=len(train_dataset),\n",
    "                            validation_data=valid_dataset,\n",
    "                            validation_steps=int(len(valid_dataset)),\n",
    "                            callbacks=[early_stopping, reduce_lr],\n",
    "                            epochs=epoch) \n",
    "    end = datetime.now()\n",
    "    print(f\"The time taken to train the model is {end - start}\")\n",
    "        \n",
    "    # Evaluate model\n",
    "    model.evaluate(test_dataset)\n",
    "    \n",
    "    # Calculate the metrics\n",
    "    # model_results = eval_metrics(model, \n",
    "    #                              test_features = test_feature,\n",
    "    #                              test_labels = test_label)\n",
    "    \n",
    "    mlflow.log_param(\"Model\"           , Model_Name)\n",
    "    mlflow.log_param(\"Dataset \", \"tdcsfog\")\n",
    "    # mlflow.log_params(model_results)\n",
    "    mlflow.tensorflow.autolog()\n",
    "    \n",
    "    \n",
    "    print(\"________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
