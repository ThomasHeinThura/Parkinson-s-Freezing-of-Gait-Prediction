{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 11:05:28.317607: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from datetime import datetime\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(1)\n",
    "tf.set_seed = 42\n",
    "\n",
    "\n",
    "train_feature = np.load('Data/defog/train_feature.npy')\n",
    "valid_feature = np.load('Data/defog/valid_feature.npy')\n",
    "test_feature = np.load('Data/defog/test_feature.npy')\n",
    "train_label = np.load('Data/defog/train_label.npy')\n",
    "valid_label = np.load('Data/defog/valid_label.npy')\n",
    "test_label = np.load('Data/defog/test_label.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29126467, 3),\n",
       " (7281617, 3),\n",
       " (29126467, 4),\n",
       " (7281617, 4),\n",
       " (9102021, 3),\n",
       " (9102021, 4))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature.shape, valid_feature.shape, train_label.shape, valid_label.shape, test_feature.shape, test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.9383897 , -0.63071996,  0.40169254],\n",
       "        [-0.74626718,  1.15504245,  0.42329343],\n",
       "        [-1.45901083,  0.82581063,  1.12756431],\n",
       "        ...,\n",
       "        [ 0.43678394, -0.47212531, -1.22587108],\n",
       "        [-0.1803416 ,  1.10619151, -0.7546232 ],\n",
       "        [ 0.09446408,  0.94949735, -0.89907782]]),\n",
       " array([[-1.04810926,  0.17965251,  0.95404327],\n",
       "        [-0.34367632, -0.82143876, -0.74641297],\n",
       "        [ 0.12979237,  1.43275645,  0.49608204],\n",
       "        ...,\n",
       "        [ 0.4771445 ,  1.08426936, -0.20847458],\n",
       "        [ 1.1514498 ,  1.15661104, -0.72467404],\n",
       "        [ 0.94376256, -0.16551092,  2.20844567]]),\n",
       " array([[-0.09736766,  1.69497109, -0.51493115],\n",
       "        [ 0.08952019,  0.3549238 ,  0.62354943],\n",
       "        [ 4.62867138,  1.84387832, -3.23883751],\n",
       "        ...,\n",
       "        [-0.51825131,  0.99459367, -0.27116491],\n",
       "        [ 0.7047527 , -0.83465243, -1.09991586],\n",
       "        [ 0.29726989, -0.26692546, -0.38839765]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature, valid_feature, test_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 11:05:30.378672: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-09 11:05:30.400104: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-09 11:05:30.400345: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-09 11:05:30.403272: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-09 11:05:30.403466: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-09 11:05:30.403599: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-09 11:05:30.981430: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-09 11:05:30.981611: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-09 11:05:30.981750: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-09 11:05:30.981863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9498 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:0a:00.0, compute capability: 8.6\n",
      "2023-05-09 11:05:30.982329: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# Building the model and pipeline for Tensorflow \n",
    "# Preprocess the data\n",
    "# Turn our data into TensorFlow Datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_feature, train_label))\n",
    "train_dataset =  train_dataset.batch(2048).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((valid_feature,valid_label))\n",
    "valid_dataset = valid_dataset.batch(2048).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_feature,test_label))\n",
    "test_dataset = test_dataset.batch(2048).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'Data/defog/'\n",
    "# train_dataset.save(path+'train_dataset')\n",
    "# valid_dataset.save(path+'valid_dataset')\n",
    "# test_dataset.save(path+'test_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'Data/defog/'\n",
    "# train_dataset = tf.data.Dataset.load(path+'train_dataset')\n",
    "# valid_dataset = tf.data.Dataset.load(path+'valid_dataset')\n",
    "# test_dataset =  tf.data.Dataset.load(path+'test_dataset')\n",
    "# test_feature = np.load('Data/defog/test_feature.npy')\n",
    "# test_label = np.load('Data/defog/test_label.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 3), dtype=tf.float64, name=None), TensorSpec(shape=(None, 4), dtype=tf.int64, name=None))> \n",
      "Valid : <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 3), dtype=tf.float64, name=None), TensorSpec(shape=(None, 4), dtype=tf.int64, name=None))> \n",
      "Test : <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 3), dtype=tf.float64, name=None), TensorSpec(shape=(None, 4), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# Check the data shape\n",
    "# print(\n",
    "#     f\"Train_feature : {train_feature.shape} {train_feature.dtype} \\n\" \n",
    "#     f\"Train_labels : {train_label.shape} {train_label.dtype} \\n\" \n",
    "#     f\"Valid_feature : {valid_feature.shape} {valid_feature.dtype} \\n\" \n",
    "#     f\"Valid_label : {valid_label.shape} {valid_label.dtype} \"\n",
    "#     ) \n",
    "\n",
    "print(f\"Train : {train_dataset} \\n\"\n",
    "      f\"Valid : {valid_dataset} \\n\" \n",
    "      f\"Test : {test_dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", # watch the val loss metric\n",
    "                                                  patience=5) # if val loss decreases for 3 epochs in a row, stop training\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",  \n",
    "                                                 factor=0.2, # multiply the learning rate by 0.2 (reduce by 5x)\n",
    "                                                 patience=3,\n",
    "                                                 verbose=1, # print out when learning rate goes down \n",
    "                                                 min_lr=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 3)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                128       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,452\n",
      "Trainable params: 4,452\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model \n",
    "epoch = 10\n",
    "input_shape = 3\n",
    "\n",
    "inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
    "x = layers.Dense(32, activation ='relu')(inputs)\n",
    "x = layers.Dense(64, activation = 'relu')(x)\n",
    "# x = layers.BatchNormalization()(x)\n",
    "# x = layers.Dropout(0.1)(x)\n",
    "# x = layers.Dense(128, activation ='relu')(x)\n",
    "# x = layers.Dense(512, activation = 'relu')(x)\n",
    "# x = layers.BatchNormalization()(x)\n",
    "# x = layers.Dropout(0.25)(x)\n",
    "# x = layers.Dense(1024, activation ='relu')(x)\n",
    "# x = layers.Dense(512, activation = 'relu')(x)\n",
    "# x = layers.BatchNormalization()(x)\n",
    "# x = layers.Dropout(0.5)(x)\n",
    "# x = layers.Dense(128, activation=\"relu\")(x)\n",
    "# x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(4, activation=\"softmax\",name=\"output_layer\")(x)      \n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(40)\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.entities import ViewType\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "# !mlflow server --backend-store-uri sqlite:///backend.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(classifier, test_features, test_labels):\n",
    "    \n",
    "    from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "    \n",
    "    # make prediction\n",
    "    model_preds_probs   = classifier.predict(test_features)\n",
    "    model_preds         = tf.argmax(model_preds_probs, axis=1)\n",
    "    predictions         = tf.argmax(test_labels,axis=1)\n",
    "\n",
    "    \n",
    "    # Calculate model accuracy\n",
    "    # model_accuracy = accuracy_score(test_labels, predictions) * 100\n",
    "    # Calculate model precision, recall and f1 score using \"weighted average\n",
    "    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(test_labels, \n",
    "                                                                                 predictions, \n",
    "                                                                                 average=\"weighted\", \n",
    "                                                                                 zero_division= 1)\n",
    "    \n",
    "    av_precision    = average_precision_score(test_labels, predictions, zero_division= 1)\n",
    "    \n",
    "    model_results = {\n",
    "        # \"accuracy\": model_accuracy,\n",
    "        \"precision\": model_precision,\n",
    "        \"recall\": model_recall,\n",
    "        \"f1\": model_f1,\n",
    "        \"av precisoin\" : av_precision}\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # target_names = ['StartHesitation','Turn','Walking', 'All_zero']\n",
    "    # print(\"Classification report\")\n",
    "    # print(\"---------------------\",\"\\n\")\n",
    "    # print(classification_report(test_labels, predictions,target_names=target_names),\"\\n\")\n",
    "    # print(\"Confusion Matrix\")\n",
    "    # print(\"---------------------\",\"\\n\")\n",
    "    # print(f\"{Matrix} \\n\")\n",
    "\n",
    "    print(\"Accuracy Measures\")\n",
    "    print(\"---------------------\",\"\\n\")\n",
    "    # print(\"Accuracy: \", model_accuracy)\n",
    "    print(\"Avarge Precision: \", av_precision)\n",
    "    print(\"precision: \", model_precision)\n",
    "    print(\"recall : \", model_recall)\n",
    "    print(\"f1 : \", model_f1)\n",
    "    \n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking URI: 'http://127.0.0.1:5000'\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# how to check tensorflow version\n",
    "tf.__version__\n",
    "len(tf.config.list_physical_devices('GPU:0'))>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 11:05:34.035338: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [29126467,4]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-05-09 11:05:35.607738: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-05-09 11:05:35.609677: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x55bbded99c10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-05-09 11:05:35.609706: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2023-05-09 11:05:35.614828: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-05-09 11:05:36.027835: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8800\n",
      "2023-05-09 11:05:36.085848: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-05-09 11:05:36.140280: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14216/14222 [============================>.] - ETA: 0s - loss: 0.8156 - accuracy: 0.6638"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 11:06:16.579590: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [7281617,4]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14222/14222 [==============================] - 52s 3ms/step - loss: 0.8156 - accuracy: 0.6638 - val_loss: 0.7653 - val_accuracy: 0.6838 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "14222/14222 [==============================] - 48s 3ms/step - loss: 0.7516 - accuracy: 0.6902 - val_loss: 0.7397 - val_accuracy: 0.6947 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "14222/14222 [==============================] - 48s 3ms/step - loss: 0.7351 - accuracy: 0.6968 - val_loss: 0.7282 - val_accuracy: 0.6981 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "14222/14222 [==============================] - 48s 3ms/step - loss: 0.7248 - accuracy: 0.7003 - val_loss: 0.7222 - val_accuracy: 0.7003 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "14222/14222 [==============================] - 48s 3ms/step - loss: 0.7180 - accuracy: 0.7029 - val_loss: 0.7178 - val_accuracy: 0.7023 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "14222/14222 [==============================] - 48s 3ms/step - loss: 0.7130 - accuracy: 0.7049 - val_loss: 0.7137 - val_accuracy: 0.7044 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "14222/14222 [==============================] - 48s 3ms/step - loss: 0.7092 - accuracy: 0.7065 - val_loss: 0.7109 - val_accuracy: 0.7054 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "14222/14222 [==============================] - 48s 3ms/step - loss: 0.7061 - accuracy: 0.7078 - val_loss: 0.7061 - val_accuracy: 0.7070 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "14222/14222 [==============================] - 48s 3ms/step - loss: 0.7036 - accuracy: 0.7088 - val_loss: 0.7038 - val_accuracy: 0.7077 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "14222/14222 [==============================] - 48s 3ms/step - loss: 0.7014 - accuracy: 0.7096 - val_loss: 0.7018 - val_accuracy: 0.7084 - lr: 0.0010\n",
      "1/1 [==============================] - 0s 80ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 11:13:37.234529: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [29126467,4]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023/05/09 11:13:42 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/usr/lib/python3.11/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time taken to train the model is 0:08:08.815583\n",
      "   1/4445 [..............................] - ETA: 5:44 - loss: 0.7017 - accuracy: 0.7109"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 11:13:42.322462: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [9102021,4]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4445/4445 [==============================] - 12s 3ms/step - loss: 0.7012 - accuracy: 0.7088\n",
      "________________________________________\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "counter = 1\n",
    "Model_Name = 'DNN_model'\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(1)\n",
    "tf.set_seed = 42\n",
    "np.random.seed(40)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.tensorflow.autolog()\n",
    "    \n",
    "    # fit the model\n",
    "    # with tf.device('/GPU:0'):\n",
    "    start = datetime.now()\n",
    "    history_model = model.fit(train_dataset,\n",
    "                            batch_size=2048,\n",
    "                            steps_per_epoch=len(train_dataset),\n",
    "                            validation_data=valid_dataset,\n",
    "                            validation_steps=int(len(valid_dataset)),\n",
    "                            callbacks=[early_stopping, reduce_lr],\n",
    "                            epochs=epoch) \n",
    "    end = datetime.now()\n",
    "    print(f\"The time taken to train the model is {end - start}\")\n",
    "        \n",
    "    # Evaluate model\n",
    "    model.evaluate(test_dataset)\n",
    "    \n",
    "    # Calculate the metrics\n",
    "    # model_results = eval_metrics(model, \n",
    "    #                              test_features = test_feature,\n",
    "    #                              test_labels = test_label)\n",
    "    \n",
    "    mlflow.log_param(\"Model\"           , Model_Name)\n",
    "    mlflow.log_param(\"Dataset\" , \"Defog\")\n",
    "    # mlflow.log_params(model_results)\n",
    "    mlflow.tensorflow.autolog()\n",
    "    \n",
    "    \n",
    "    print(\"________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
